//! Tests for the sparse embedding model.
//!
//! These tests cover construction, trait implementation, state transitions,
//! embedding behavior, and sparse vector operations.

#[cfg(test)]
#[allow(clippy::module_inception)]
mod tests {
    use std::path::PathBuf;

    use crate::error::EmbeddingError;
    use crate::models::pretrained::sparse::{
        SparseModel, SparseVector, SPARSE_HIDDEN_SIZE, SPARSE_LATENCY_BUDGET_MS, SPARSE_MAX_TOKENS,
        SPARSE_MODEL_NAME, SPARSE_VOCAB_SIZE,
    };
    use crate::traits::{EmbeddingModel, SingleModelConfig};
    use crate::types::{ModelId, ModelInput};

    /// Get the workspace root directory for test model paths.
    /// Uses CARGO_MANIFEST_DIR (crate dir) and navigates up to workspace root.
    fn workspace_root() -> PathBuf {
        let manifest_dir = std::env::var("CARGO_MANIFEST_DIR").unwrap_or_else(|_| ".".to_string());
        PathBuf::from(manifest_dir)
            .parent() // -> crates/
            .and_then(|p| p.parent()) // -> workspace root
            .map(|p| p.to_path_buf())
            .unwrap_or_else(|| PathBuf::from("."))
    }

    fn create_test_model() -> SparseModel {
        let model_path = workspace_root().join("models/sparse");
        SparseModel::new(&model_path, SingleModelConfig::default())
            .expect("Failed to create SparseModel")
    }

    async fn create_and_load_model() -> SparseModel {
        let model = create_test_model();
        model.load().await.expect("Failed to load model");
        model
    }

    // ==================== Construction Tests ====================

    #[test]
    fn test_new_creates_unloaded_model() {
        let model = create_test_model();
        assert!(!model.is_initialized());
    }

    #[test]
    fn test_new_with_zero_batch_size_fails() {
        let config = SingleModelConfig {
            max_batch_size: 0,
            ..Default::default()
        };
        let model_path = workspace_root().join("models/sparse");
        let result = SparseModel::new(&model_path, config);
        assert!(matches!(result, Err(EmbeddingError::ConfigError { .. })));
    }

    // ==================== Trait Implementation Tests ====================

    #[test]
    fn test_model_id() {
        let model = create_test_model();
        assert_eq!(model.model_id(), ModelId::Sparse);
    }

    #[test]
    fn test_dimension() {
        let model = create_test_model();
        // SPLADE uses sparse vocabulary-sized vectors (30522 = BERT vocab size)
        assert_eq!(model.dimension(), 30522);
    }

    #[test]
    fn test_max_tokens() {
        let model = create_test_model();
        assert_eq!(model.max_tokens(), 512);
    }

    #[test]
    fn test_latency_budget_ms() {
        let model = create_test_model();
        // SPLADE has 3ms target latency (fast sparse inference)
        assert_eq!(model.latency_budget_ms(), 3);
    }

    #[test]
    fn test_is_pretrained() {
        let model = create_test_model();
        assert!(model.is_pretrained());
    }

    #[test]
    fn test_supported_input_types() {
        let model = create_test_model();
        assert_eq!(
            model.supported_input_types(),
            &[crate::types::InputType::Text]
        );
    }

    // ==================== State Transition Tests ====================

    #[tokio::test]
    async fn test_load_sets_initialized() {
        let model = create_test_model();
        assert!(!model.is_initialized());
        model.load().await.expect("Load should succeed");
        assert!(model.is_initialized());
    }

    #[tokio::test]
    async fn test_unload_clears_initialized() {
        let model = create_and_load_model().await;
        assert!(model.is_initialized());
        model.unload().await.expect("Unload should succeed");
        assert!(!model.is_initialized());
    }

    #[tokio::test]
    async fn test_unload_when_not_loaded_fails() {
        let model = create_test_model();
        let result = model.unload().await;
        assert!(matches!(result, Err(EmbeddingError::NotInitialized { .. })));
    }

    // ==================== Embedding Tests ====================

    #[tokio::test]
    async fn test_embed_before_load_fails() {
        let model = create_test_model();
        let input = ModelInput::text("test").expect("Failed to create input");
        let result = model.embed(&input).await;
        assert!(matches!(result, Err(EmbeddingError::NotInitialized { .. })));
    }

    #[tokio::test]
    #[should_panic(expected = "EMB-MIGRATION")]
    async fn test_embed_panics_until_projection_ready() {
        let model = create_and_load_model().await;
        let input = ModelInput::text("Test sparse embedding").expect("Input");

        // This SHOULD panic until ProjectionMatrix integration is complete
        let _ = model.embed(&input).await;
    }

    #[tokio::test]
    async fn test_embed_unsupported_modality() {
        let model = create_and_load_model().await;
        let input = ModelInput::code("fn main() {}", "rust").expect("Input");

        let result = model.embed(&input).await;
        assert!(matches!(
            result,
            Err(EmbeddingError::UnsupportedModality { .. })
        ));
    }

    // ==================== Sparse Vector Tests ====================

    #[test]
    fn test_sparse_vector_new() {
        let indices = vec![10, 100, 500];
        let weights = vec![0.5, 0.3, 0.8];
        let sparse = SparseVector::new(indices.clone(), weights.clone());

        assert_eq!(sparse.indices, indices);
        assert_eq!(sparse.weights, weights);
        assert_eq!(sparse.dimension, SPARSE_VOCAB_SIZE);
        assert_eq!(sparse.dimension, 30522);
    }

    #[test]
    fn test_sparse_vector_to_csr() {
        let sparse = SparseVector::new(vec![10, 100, 500], vec![0.5, 0.3, 0.8]);
        let (row_ptr, col_indices, values) = sparse.to_csr();

        // CSR format verification
        assert_eq!(row_ptr, vec![0, 3], "row_ptr must be [0, nnz]");
        assert_eq!(col_indices, vec![10, 100, 500], "col_indices must match indices as i32");
        assert_eq!(values, vec![0.5, 0.3, 0.8], "values must match weights");
    }

    #[test]
    fn test_sparse_vector_to_csr_empty() {
        // EDGE CASE 1: Empty sparse vector (boundary - empty input)
        let sparse = SparseVector::new(vec![], vec![]);
        let (row_ptr, col_indices, values) = sparse.to_csr();

        assert_eq!(row_ptr, vec![0, 0], "Empty vector: row_ptr = [0, 0]");
        assert!(col_indices.is_empty(), "Empty vector: no col_indices");
        assert!(values.is_empty(), "Empty vector: no values");
        assert_eq!(sparse.nnz(), 0, "Empty vector: nnz = 0");
    }

    #[test]
    fn test_sparse_vector_to_csr_single_element() {
        // EDGE CASE 2: Single element (boundary - minimum non-empty)
        let sparse = SparseVector::new(vec![12345], vec![0.99]);
        let (row_ptr, col_indices, values) = sparse.to_csr();

        assert_eq!(row_ptr, vec![0, 1], "Single element: row_ptr = [0, 1]");
        assert_eq!(col_indices, vec![12345], "Single element: col_indices");
        assert_eq!(values, vec![0.99], "Single element: values");
        assert_eq!(sparse.nnz(), 1, "Single element: nnz = 1");
    }

    #[test]
    fn test_sparse_vector_to_csr_max_index() {
        // EDGE CASE 3: Maximum valid index (boundary - max vocab index)
        let max_idx = SPARSE_VOCAB_SIZE - 1; // 30521
        let sparse = SparseVector::new(vec![0, max_idx], vec![0.1, 0.2]);
        let (row_ptr, col_indices, values) = sparse.to_csr();

        assert_eq!(row_ptr, vec![0, 2]);
        assert_eq!(col_indices, vec![0, 30521]);
        assert_eq!(values, vec![0.1, 0.2]);
    }

    #[test]
    fn test_sparse_vector_nnz() {
        let sparse = SparseVector::new(vec![0, 100, 500, 1000, 2000], vec![0.1, 0.2, 0.3, 0.4, 0.5]);
        assert_eq!(sparse.nnz(), 5);
    }

    #[test]
    fn test_sparse_vector_sparsity() {
        let sparse = SparseVector::new(vec![0, 100, 500], vec![1.0, 0.5, 0.8]);

        // 3 non-zero out of 30522 = ~99.99% sparse
        let sparsity = sparse.sparsity();
        assert!(sparsity > 0.99, "Sparsity should be >99%, got {}", sparsity);

        // More precise check: 1.0 - 3/30522 = 0.999901...
        let expected = 1.0 - (3.0 / 30522.0);
        assert!((sparsity - expected).abs() < 0.0001, "Sparsity mismatch: {} vs {}", sparsity, expected);
    }

    #[test]
    fn test_sparse_vector_default() {
        let sparse = SparseVector::default();
        assert!(sparse.indices.is_empty());
        assert!(sparse.weights.is_empty());
        assert_eq!(sparse.dimension, SPARSE_VOCAB_SIZE);
        assert_eq!(sparse.nnz(), 0);
        assert_eq!(sparse.sparsity(), 1.0);
    }

    #[test]
    fn test_sparse_vector_equality() {
        let sparse1 = SparseVector::new(vec![10, 20], vec![0.5, 0.6]);
        let sparse2 = SparseVector::new(vec![10, 20], vec![0.5, 0.6]);
        let sparse3 = SparseVector::new(vec![10, 20], vec![0.5, 0.7]);

        assert_eq!(sparse1, sparse2, "Same content should be equal");
        assert_ne!(sparse1, sparse3, "Different weights should not be equal");
    }

    // ==================== Constants Tests ====================

    #[test]
    fn test_constants_are_correct() {
        assert_eq!(SPARSE_VOCAB_SIZE, 30522);
        assert_eq!(SPARSE_HIDDEN_SIZE, 768);
        assert_eq!(SPARSE_MAX_TOKENS, 512);
        assert_eq!(SPARSE_LATENCY_BUDGET_MS, 10);
        assert_eq!(SPARSE_MODEL_NAME, "naver/splade-cocondenser-ensembledistil");
    }
}
