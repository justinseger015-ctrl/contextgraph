[package]
name = "context-graph-embeddings"
version = "0.1.0"
edition = "2021"
authors = ["Context Graph Team"]
description = "Embedding pipeline for Context Graph with local model support"
license = "MIT"
repository = "https://github.com/contextgraph/contextgraph"
keywords = ["embeddings", "ml", "nlp", "context-graph"]

[dependencies]
context-graph-core = { path = "../context-graph-core" }

# Async runtime
tokio = { workspace = true }

# Serialization
serde = { workspace = true }
serde_json = "1.0"

# Error handling
thiserror = { workspace = true }
async-trait = { workspace = true }

# Logging
tracing = { workspace = true }

# For stub implementations and Gaussian noise in gating network
rand = "0.8"
rand_distr = "0.4"

# UUID for request tracking
uuid = { version = "1.0", features = ["v4"] }

# Configuration
toml = "0.8"

# Hashing for content deduplication
xxhash-rust = { version = "0.8", features = ["xxh64"] }

# Time handling for temporal embeddings
chrono = { version = "0.4", features = ["serde"] }

# Lazy static initialization for cache timestamps
once_cell = "1.19"

# Zero-copy binary serialization for GDS-compatible storage
bytemuck = { version = "1.14", features = ["derive"] }

# Efficient bit vector operations for HDC (Hyperdimensional Computing) model
bitvec = "1.0"

# Image processing for CLIP multimodal embeddings
image = { version = "0.25", default-features = false, features = ["png", "jpeg"] }

# LRU cache with O(1) operations for CacheManager
linked-hash-map = "0.5"

# Fast binary serialization for cache persistence
bincode = "1.3"

[dev-dependencies]
tokio-test = "0.4"
tempfile = "3.10"
serial_test = "3.0"

[features]
default = ["stub"]
stub = []
onnx = []  # Future: ONNX Runtime support
candle = []  # Future: Candle ML support
