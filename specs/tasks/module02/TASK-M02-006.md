# TASK-M02-006: Implement MemoryNode Methods

```xml
<task_spec id="TASK-M02-006" version="1.0">
<metadata>
  <title>Implement MemoryNode Methods</title>
  <status>blocked</status>
  <layer>foundation</layer>
  <module>module-02</module>
  <sequence>6</sequence>
  <priority>critical</priority>
  <estimated_hours>3</estimated_hours>
  <implements>
    <item>REQ-CORE-004: Memory decay requirements</item>
    <item>TECH-CORE-002 Section 2.1: MemoryNode methods specification</item>
  </implements>
  <depends_on>
    <task_ref>TASK-M02-005</task_ref>
  </depends_on>
  <estimated_complexity>medium</estimated_complexity>
</metadata>

<context>
This task implements all methods for the MemoryNode struct including constructors, access tracking, decay computation using the Ebbinghaus forgetting curve, consolidation logic, and comprehensive validation. These methods enable the core lifecycle management of memory nodes in the Context Graph system.
</context>

<input_context_files>
  <file purpose="MemoryNode struct definition">crates/context-graph-core/src/memory_node.rs</file>
  <file purpose="Constitution reference for validation rules">docs2/constitution.yaml</file>
  <file purpose="PRD reference for decay formula">docs2/contextprd.md</file>
</input_context_files>

<prerequisites>
  <check>TASK-M02-005 (MemoryNode struct) is complete</check>
  <check>ValidationError enum is available</check>
</prerequisites>

<scope>
  <in_scope>
    - MemoryNode::new() constructor
    - MemoryNode::with_id() constructor with specific ID
    - MemoryNode::record_access() method
    - MemoryNode::age_seconds() method
    - MemoryNode::time_since_access_seconds() method
    - MemoryNode::compute_decay() method (Ebbinghaus curve)
    - MemoryNode::should_consolidate() method
    - MemoryNode::validate() method
    - Default trait implementation
    - Comprehensive unit tests
  </in_scope>
  <out_of_scope>
    - Storage operations (handled in storage tasks)
    - UTL score computation (handled in UTL module)
  </out_of_scope>
</scope>

<definition_of_done>
  <signatures>
    <signature file="crates/context-graph-core/src/memory_node.rs">
/// Tolerance for embedding normalization check.
const NORMALIZATION_TOLERANCE: f64 = 0.01;

/// Consolidation threshold score.
const CONSOLIDATION_THRESHOLD: f32 = 0.7;

impl MemoryNode {
    /// Create a new MemoryNode with generated UUID and current timestamps.
    ///
    /// # Arguments
    /// * `content` - The content to store
    /// * `embedding` - The embedding vector (should be 1536 dimensions)
    ///
    /// # Example
    /// ```
    /// let node = MemoryNode::new("Hello world".to_string(), vec![0.0; 1536]);
    /// ```
    pub fn new(content: String, embedding: EmbeddingVector) -> Self;

    /// Create a new MemoryNode with a specific ID.
    pub fn with_id(id: NodeId, content: String, embedding: EmbeddingVector) -> Self;

    /// Record an access to this node, updating accessed_at and incrementing access_count.
    pub fn record_access(&amp;mut self);

    /// Get the age of this node in seconds since creation.
    pub fn age_seconds(&amp;self) -> i64;

    /// Get the time since last access in seconds.
    pub fn time_since_access_seconds(&amp;self) -> i64;

    /// Compute memory decay using modified Ebbinghaus forgetting curve.
    ///
    /// Formula: R = e^(-t / (S * k))
    /// Where:
    /// - R = retention (0.0 to 1.0)
    /// - t = time since access in hours
    /// - S = memory strength (based on access_count)
    /// - k = importance factor
    ///
    /// Returns a value between 0.0 (forgotten) and 1.0 (fully retained).
    pub fn compute_decay(&amp;self) -> f32;

    /// Determine if this node should be consolidated based on weighted score.
    ///
    /// Score = 0.4 * importance + 0.3 * (1 - decay) + 0.3 * access_frequency
    /// Returns true if score >= CONSOLIDATION_THRESHOLD (0.7)
    pub fn should_consolidate(&amp;self) -> bool;

    /// Validate all node constraints.
    ///
    /// Checks:
    /// - Embedding dimension is 1536
    /// - Importance is in [0.0, 1.0]
    /// - Emotional valence is in [-1.0, 1.0]
    /// - Content size is <= 1MB
    /// - Embedding is normalized (magnitude ≈ 1.0)
    ///
    /// Returns Ok(()) if valid, Err(ValidationError) otherwise.
    pub fn validate(&amp;self) -> Result&lt;(), ValidationError&gt;;
}

impl Default for MemoryNode {
    fn default() -> Self;
}
    </signature>
  </signatures>

  <constraints>
    - new() creates node with UUID v4 and current UTC timestamps
    - record_access() uses saturating_add for access_count to prevent overflow
    - compute_decay() must handle edge cases (zero time, zero access)
    - validate() checks in order: embedding dim, importance, valence, content size, normalization
    - Embedding normalization check uses tolerance of ±0.01 (magnitude in [0.99, 1.01])
    - Default creates empty content and zero-filled embedding of correct size
    - Follow AP-009: Clamp/validate numeric values to prevent NaN/Infinity
  </constraints>

  <verification>
    - cargo build --package context-graph-core compiles without errors
    - cargo test --package context-graph-core memory_node passes all tests
    - cargo clippy --package context-graph-core shows no warnings
  </verification>
</definition_of_done>

<pseudo_code>
memory_node.rs (append after MemoryNode struct):
  const NORMALIZATION_TOLERANCE: f64 = 0.01;
  const CONSOLIDATION_THRESHOLD: f32 = 0.7;

  impl MemoryNode:
    fn new(content, embedding):
      let now = Utc::now();
      Self {
        id: Uuid::new_v4(),
        content,
        embedding,
        quadrant: JohariQuadrant::default(),  // Open
        importance: 0.5,
        emotional_valence: 0.0,
        created_at: now,
        accessed_at: now,
        access_count: 0,
        metadata: NodeMetadata::default(),
      }

    fn with_id(id, content, embedding):
      let mut node = Self::new(content, embedding);
      node.id = id;
      node

    fn record_access(&amp;mut self):
      self.accessed_at = Utc::now();
      self.access_count = self.access_count.saturating_add(1);

    fn age_seconds(&amp;self):
      (Utc::now() - self.created_at).num_seconds()

    fn time_since_access_seconds(&amp;self):
      (Utc::now() - self.accessed_at).num_seconds()

    fn compute_decay(&amp;self):
      // Modified Ebbinghaus: R = e^(-t / (S * k))
      let t_hours = self.time_since_access_seconds() as f64 / 3600.0;
      let strength = 1.0 + (self.access_count as f64).ln().max(0.0);
      let k = 1.0 + self.importance as f64;
      let decay = (-t_hours / (strength * k * 24.0)).exp();  // 24h baseline
      decay.clamp(0.0, 1.0) as f32

    fn should_consolidate(&amp;self):
      let decay = self.compute_decay();
      let access_freq = (self.access_count as f32 / self.age_seconds().max(1) as f32 * 3600.0).min(1.0);
      let score = 0.4 * self.importance + 0.3 * (1.0 - decay) + 0.3 * access_freq;
      score >= CONSOLIDATION_THRESHOLD

    fn validate(&amp;self):
      // Check embedding dimension
      if self.embedding.len() != DEFAULT_EMBEDDING_DIM:
        return Err(ValidationError::InvalidEmbeddingDimension {
          expected: DEFAULT_EMBEDDING_DIM,
          actual: self.embedding.len()
        })

      // Check importance range
      if self.importance < 0.0 || self.importance > 1.0:
        return Err(ValidationError::OutOfBounds {
          field: "importance".to_string(),
          value: self.importance as f64,
          min: 0.0, max: 1.0
        })

      // Check emotional valence range
      if self.emotional_valence < -1.0 || self.emotional_valence > 1.0:
        return Err(ValidationError::OutOfBounds {
          field: "emotional_valence".to_string(),
          value: self.emotional_valence as f64,
          min: -1.0, max: 1.0
        })

      // Check content size
      if self.content.len() > MAX_CONTENT_SIZE:
        return Err(ValidationError::ContentTooLarge {
          size: self.content.len(),
          max_size: MAX_CONTENT_SIZE
        })

      // Check embedding normalization
      let magnitude: f64 = self.embedding.iter().map(|x| (*x as f64).powi(2)).sum::<f64>().sqrt();
      if (magnitude - 1.0).abs() > NORMALIZATION_TOLERANCE:
        return Err(ValidationError::EmbeddingNotNormalized { magnitude })

      Ok(())

  impl Default:
    fn default():
      Self::new(String::new(), vec![0.0; DEFAULT_EMBEDDING_DIM])

#[cfg(test)]
mod memory_node_method_tests:
  test_new_creates_valid_node()
  test_with_id_preserves_id()
  test_record_access_updates_timestamp()
  test_record_access_increments_count()
  test_record_access_saturates()
  test_age_seconds()
  test_time_since_access()
  test_compute_decay_recent_access()
  test_compute_decay_old_access()
  test_should_consolidate_high_importance()
  test_should_consolidate_low_importance()
  test_validate_valid_node()
  test_validate_wrong_embedding_dim()
  test_validate_importance_out_of_bounds()
  test_validate_valence_out_of_bounds()
  test_validate_content_too_large()
  test_validate_embedding_not_normalized()
  test_default_creates_valid_node()
</pseudo_code>

<files_to_create>
  <!-- File already exists -->
</files_to_create>

<files_to_modify>
  <file path="crates/context-graph-core/src/memory_node.rs">Add MemoryNode methods and Default implementation</file>
</files_to_modify>

<validation_criteria>
  <criterion>new() creates node with UUID v4 and current timestamps</criterion>
  <criterion>record_access() updates accessed_at and increments access_count safely</criterion>
  <criterion>compute_decay() implements modified Ebbinghaus formula correctly</criterion>
  <criterion>compute_decay() returns value in [0.0, 1.0] range</criterion>
  <criterion>should_consolidate() threshold is 0.7 based on weighted score formula</criterion>
  <criterion>validate() checks embedding dim first (1536)</criterion>
  <criterion>validate() checks importance in [0.0, 1.0]</criterion>
  <criterion>validate() checks emotional_valence in [-1.0, 1.0]</criterion>
  <criterion>validate() checks content size ≤ 1MB</criterion>
  <criterion>validate() checks embedding normalization with tolerance ±0.01</criterion>
  <criterion>All validation errors return correct ValidationError variants</criterion>
  <criterion>Default creates empty node with zero-filled embedding</criterion>
</validation_criteria>

<test_commands>
  <command>cargo build --package context-graph-core</command>
  <command>cargo test --package context-graph-core memory_node -- --nocapture</command>
  <command>cargo clippy --package context-graph-core -- -D warnings</command>
</test_commands>
</task_spec>
```

## Implementation Notes

### Ebbinghaus Forgetting Curve
The modified Ebbinghaus formula: R = e^(-t / (S * k))
- R = retention (0.0 to 1.0)
- t = time since access in hours
- S = memory strength factor based on access_count: 1 + ln(access_count + 1)
- k = importance factor: 1 + importance

### Consolidation Score Formula
```
score = 0.4 * importance + 0.3 * (1 - decay) + 0.3 * access_frequency
```
- Higher importance → higher score
- Higher decay (more forgotten) → lower score
- Higher access frequency → higher score

### Normalization Check
Embedding vectors should be unit normalized (magnitude ≈ 1.0).
The check uses a tolerance of ±0.01 to account for floating-point precision:
```rust
let magnitude = embedding.iter().map(|x| x.powi(2)).sum::<f32>().sqrt();
(magnitude - 1.0).abs() <= 0.01
```

---

*Task ID: TASK-M02-006*
*Module: 02 - Core Infrastructure*
*Layer: Foundation*
