# TASK-M02-016: Implement RocksDB Backend Open/Close

## Task Metadata
| Field | Value |
|-------|-------|
| **Status** | ⏳ READY |
| **Layer** | logic |
| **Priority** | critical |
| **Depends On** | TASK-M02-014 ✅, TASK-M02-015 ✅ |
| **Estimated Hours** | 3 |
| **Implements** | TECH-CORE-002 Section 3.2: RocksDB backend specification |

---

## Critical Context for AI Agent

**You are implementing the RocksDB database connection management for Context Graph.** This is the foundation for ALL persistent storage operations in the system.

### What This Task Does
- Opens a RocksDB database with all 12 column families
- Configures the shared 256MB block cache
- Sets up WAL (Write-Ahead Logging) for durability
- Provides safe resource cleanup when the database is dropped

### What This Task Does NOT Do
- CRUD operations for nodes/edges (TASK-M02-017, TASK-M02-018)
- Memex trait implementation (TASK-M02-026)
- Secondary index queries (TASK-M02-023)

---

## Current Codebase State (Verified 2025-12-31)

### Files That ALREADY EXIST and ARE COMPLETE

| File | Status | Description |
|------|--------|-------------|
| `crates/context-graph-storage/src/lib.rs` | ✅ COMPLETE | Module exports, re-exports all types |
| `crates/context-graph-storage/src/column_families.rs` | ✅ COMPLETE | All 12 CFs, 23 tests passing |
| `crates/context-graph-storage/src/serialization.rs` | ✅ COMPLETE | Hybrid msgpack+bincode, 41 tests passing |
| `crates/context-graph-storage/Cargo.toml` | ✅ COMPLETE | rocksdb="0.22", tempfile="3.10" |

### File You Must Modify

| File | Current State | Action |
|------|---------------|--------|
| `crates/context-graph-storage/src/rocksdb_backend.rs` | Placeholder (14 lines, TODO comment) | IMPLEMENT FULLY |

### Key Dependencies Already Available

```rust
// From column_families.rs (ALREADY EXISTS)
use crate::column_families::{cf_names, get_column_family_descriptors};
// cf_names::ALL contains 12 CF names
// cf_names::NODES, cf_names::EDGES, etc.

// From serialization.rs (ALREADY EXISTS)
use crate::serialization::SerializationError;

// From context-graph-core (ALREADY EXISTS)
use context_graph_core::types::{NodeId, EdgeId};
```

---

## Required Implementation

### File: `crates/context-graph-storage/src/rocksdb_backend.rs`

```rust
//! RocksDB storage backend implementation.
//!
//! Provides persistent storage using RocksDB with column families
//! for Johari quadrant separation and efficient indexing.
//!
//! # Performance Targets (constitution.yaml)
//! - inject_context: p95 < 25ms, p99 < 50ms
//! - hopfield: < 1ms
//!
//! # Column Families
//! Uses 12 CFs defined in `column_families.rs`:
//! - nodes, edges, embeddings, metadata
//! - johari_open, johari_hidden, johari_blind, johari_unknown
//! - temporal, tags, sources, system

use rocksdb::{Cache, ColumnFamily, Options, DB};
use std::path::Path;
use thiserror::Error;

use crate::column_families::{cf_names, get_column_family_descriptors};

/// Default block cache size: 256MB (per constitution.yaml).
pub const DEFAULT_CACHE_SIZE: usize = 256 * 1024 * 1024;

/// Default maximum open files.
pub const DEFAULT_MAX_OPEN_FILES: i32 = 1000;

/// Storage operation errors.
///
/// These errors cover database lifecycle operations.
/// For serialization errors, see `SerializationError`.
#[derive(Debug, Error)]
pub enum StorageError {
    /// Database failed to open.
    #[error("Failed to open database at '{path}': {message}")]
    OpenFailed { path: String, message: String },

    /// Column family not found (should never happen if DB opened correctly).
    #[error("Column family '{name}' not found")]
    ColumnFamilyNotFound { name: String },

    /// Write operation failed.
    #[error("Write failed: {0}")]
    WriteFailed(String),

    /// Read operation failed.
    #[error("Read failed: {0}")]
    ReadFailed(String),

    /// Flush operation failed.
    #[error("Flush failed: {0}")]
    FlushFailed(String),
}

/// Configuration options for RocksDbMemex.
///
/// # Defaults
/// - `max_open_files`: 1000
/// - `block_cache_size`: 256MB (268,435,456 bytes)
/// - `enable_wal`: true (durability)
/// - `create_if_missing`: true (convenience)
#[derive(Debug, Clone)]
pub struct RocksDbConfig {
    /// Maximum open files (default: 1000).
    pub max_open_files: i32,
    /// Block cache size in bytes (default: 256MB).
    pub block_cache_size: usize,
    /// Enable Write-Ahead Logging (default: true).
    pub enable_wal: bool,
    /// Create database if missing (default: true).
    pub create_if_missing: bool,
}

impl Default for RocksDbConfig {
    fn default() -> Self {
        Self {
            max_open_files: DEFAULT_MAX_OPEN_FILES,
            block_cache_size: DEFAULT_CACHE_SIZE,
            enable_wal: true,
            create_if_missing: true,
        }
    }
}

/// RocksDB-backed storage implementation.
///
/// Provides persistent storage for MemoryNodes and GraphEdges with
/// optimized column families for different access patterns.
///
/// # Thread Safety
/// RocksDB's `DB` type is internally thread-safe for concurrent reads and writes.
/// This struct can be shared across threads via `Arc<RocksDbMemex>`.
///
/// # Column Families
/// Opens all 12 column families defined in `column_families.rs`.
///
/// # Example
/// ```rust,ignore
/// use context_graph_storage::rocksdb_backend::{RocksDbMemex, RocksDbConfig};
/// use tempfile::TempDir;
///
/// let tmp = TempDir::new().unwrap();
/// let db = RocksDbMemex::open(tmp.path()).expect("open failed");
/// assert!(db.health_check().is_ok());
/// ```
pub struct RocksDbMemex {
    /// The RocksDB database instance.
    db: DB,
    /// Shared block cache (kept alive for DB lifetime).
    #[allow(dead_code)]
    cache: Cache,
    /// Database path for reference.
    path: String,
}

impl RocksDbMemex {
    /// Open a RocksDB database at the specified path with default configuration.
    ///
    /// Creates the database and all 12 column families if they don't exist.
    ///
    /// # Arguments
    /// * `path` - Path to the database directory
    ///
    /// # Returns
    /// * `Ok(RocksDbMemex)` - Successfully opened database
    /// * `Err(StorageError::OpenFailed)` - Database could not be opened
    ///
    /// # Example
    /// ```rust,ignore
    /// use context_graph_storage::rocksdb_backend::RocksDbMemex;
    /// use tempfile::TempDir;
    ///
    /// let tmp = TempDir::new().unwrap();
    /// let db = RocksDbMemex::open(tmp.path()).expect("open failed");
    /// ```
    pub fn open<P: AsRef<Path>>(path: P) -> Result<Self, StorageError> {
        Self::open_with_config(path, RocksDbConfig::default())
    }

    /// Open a RocksDB database with custom configuration.
    ///
    /// # Arguments
    /// * `path` - Path to the database directory
    /// * `config` - Custom configuration options
    ///
    /// # Returns
    /// * `Ok(RocksDbMemex)` - Successfully opened database
    /// * `Err(StorageError::OpenFailed)` - Database could not be opened
    pub fn open_with_config<P: AsRef<Path>>(
        path: P,
        config: RocksDbConfig,
    ) -> Result<Self, StorageError> {
        let path_str = path.as_ref().to_string_lossy().to_string();

        // Create shared block cache
        let cache = Cache::new_lru_cache(config.block_cache_size);

        // Create DB options
        let mut db_opts = Options::default();
        db_opts.create_if_missing(config.create_if_missing);
        db_opts.create_missing_column_families(true);
        db_opts.set_max_open_files(config.max_open_files);

        // WAL configuration
        if !config.enable_wal {
            db_opts.set_manual_wal_flush(true);
        }

        // Get column family descriptors with optimized options
        let cf_descriptors = get_column_family_descriptors(&cache);

        // Open database with all column families
        let db = DB::open_cf_descriptors(&db_opts, &path_str, cf_descriptors).map_err(|e| {
            StorageError::OpenFailed {
                path: path_str.clone(),
                message: e.to_string(),
            }
        })?;

        Ok(Self {
            db,
            cache,
            path: path_str,
        })
    }

    /// Get a reference to a column family by name.
    ///
    /// # Arguments
    /// * `name` - Column family name (use `cf_names::*` constants)
    ///
    /// # Returns
    /// * `Ok(&ColumnFamily)` - Reference to the column family
    /// * `Err(StorageError::ColumnFamilyNotFound)` - CF doesn't exist
    ///
    /// # Example
    /// ```rust,ignore
    /// use context_graph_storage::rocksdb_backend::RocksDbMemex;
    /// use context_graph_storage::column_families::cf_names;
    ///
    /// let cf = db.get_cf(cf_names::NODES)?;
    /// ```
    pub fn get_cf(&self, name: &str) -> Result<&ColumnFamily, StorageError> {
        self.db
            .cf_handle(name)
            .ok_or_else(|| StorageError::ColumnFamilyNotFound {
                name: name.to_string(),
            })
    }

    /// Get the database path.
    ///
    /// # Returns
    /// The path where the database is stored.
    pub fn path(&self) -> &str {
        &self.path
    }

    /// Check if the database is healthy.
    ///
    /// Verifies all 12 column families are accessible.
    ///
    /// # Returns
    /// * `Ok(())` - All CFs accessible
    /// * `Err(StorageError::ColumnFamilyNotFound)` - A CF is missing
    pub fn health_check(&self) -> Result<(), StorageError> {
        for cf_name in cf_names::ALL {
            self.get_cf(cf_name)?;
        }
        Ok(())
    }

    /// Flush all column families to disk.
    ///
    /// Forces all buffered writes to be persisted.
    ///
    /// # Returns
    /// * `Ok(())` - All CFs flushed successfully
    /// * `Err(StorageError::FlushFailed)` - Flush operation failed
    pub fn flush_all(&self) -> Result<(), StorageError> {
        for cf_name in cf_names::ALL {
            let cf = self.get_cf(cf_name)?;
            self.db
                .flush_cf(cf)
                .map_err(|e| StorageError::FlushFailed(e.to_string()))?;
        }
        Ok(())
    }

    /// Get a reference to the underlying RocksDB instance.
    ///
    /// Use this for advanced operations not covered by the high-level API.
    /// Be careful not to violate data invariants.
    pub fn db(&self) -> &DB {
        &self.db
    }
}

// DB is automatically closed when RocksDbMemex is dropped (RocksDB's Drop impl)

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    // =========================================================================
    // Helper Functions
    // =========================================================================

    fn create_temp_db() -> (TempDir, RocksDbMemex) {
        let tmp = TempDir::new().expect("Failed to create temp dir");
        let db = RocksDbMemex::open(tmp.path()).expect("Failed to open database");
        (tmp, db)
    }

    // =========================================================================
    // RocksDbConfig Tests
    // =========================================================================

    #[test]
    fn test_config_default_values() {
        let config = RocksDbConfig::default();
        assert_eq!(config.max_open_files, 1000);
        assert_eq!(config.block_cache_size, 256 * 1024 * 1024);
        assert!(config.enable_wal);
        assert!(config.create_if_missing);
    }

    #[test]
    fn test_config_custom_values() {
        let config = RocksDbConfig {
            max_open_files: 500,
            block_cache_size: 128 * 1024 * 1024,
            enable_wal: false,
            create_if_missing: false,
        };
        assert_eq!(config.max_open_files, 500);
        assert_eq!(config.block_cache_size, 128 * 1024 * 1024);
        assert!(!config.enable_wal);
        assert!(!config.create_if_missing);
    }

    #[test]
    fn test_config_clone() {
        let config = RocksDbConfig::default();
        let cloned = config.clone();
        assert_eq!(config.max_open_files, cloned.max_open_files);
    }

    #[test]
    fn test_config_debug() {
        let config = RocksDbConfig::default();
        let debug = format!("{:?}", config);
        assert!(debug.contains("RocksDbConfig"));
        assert!(debug.contains("max_open_files"));
    }

    // =========================================================================
    // StorageError Tests
    // =========================================================================

    #[test]
    fn test_error_open_failed() {
        let error = StorageError::OpenFailed {
            path: "/tmp/test".to_string(),
            message: "permission denied".to_string(),
        };
        let msg = error.to_string();
        assert!(msg.contains("/tmp/test"));
        assert!(msg.contains("permission denied"));
    }

    #[test]
    fn test_error_column_family_not_found() {
        let error = StorageError::ColumnFamilyNotFound {
            name: "unknown_cf".to_string(),
        };
        let msg = error.to_string();
        assert!(msg.contains("unknown_cf"));
    }

    #[test]
    fn test_error_write_failed() {
        let error = StorageError::WriteFailed("disk full".to_string());
        assert!(error.to_string().contains("disk full"));
    }

    #[test]
    fn test_error_read_failed() {
        let error = StorageError::ReadFailed("io error".to_string());
        assert!(error.to_string().contains("io error"));
    }

    #[test]
    fn test_error_flush_failed() {
        let error = StorageError::FlushFailed("sync failed".to_string());
        assert!(error.to_string().contains("sync failed"));
    }

    #[test]
    fn test_error_debug() {
        let error = StorageError::WriteFailed("test".to_string());
        let debug = format!("{:?}", error);
        assert!(debug.contains("WriteFailed"));
    }

    // =========================================================================
    // Database Open/Close Tests
    // =========================================================================

    #[test]
    fn test_open_creates_database() {
        println!("=== TEST: open() creates database ===");
        let tmp = TempDir::new().expect("create temp dir");
        let path = tmp.path();

        println!("BEFORE: Database path = {:?}", path);
        println!("BEFORE: Path exists = {}", path.exists());

        let db = RocksDbMemex::open(path).expect("open failed");

        println!("AFTER: Database opened successfully");
        println!("AFTER: db.path() = {}", db.path());

        assert!(path.exists(), "Database directory should exist");
        assert_eq!(db.path(), path.to_string_lossy());
    }

    #[test]
    fn test_open_with_custom_config() {
        println!("=== TEST: open_with_config() custom settings ===");
        let tmp = TempDir::new().expect("create temp dir");

        let config = RocksDbConfig {
            max_open_files: 100,
            block_cache_size: 64 * 1024 * 1024, // 64MB
            enable_wal: true,
            create_if_missing: true,
        };

        println!("BEFORE: Custom config = {:?}", config);

        let db = RocksDbMemex::open_with_config(tmp.path(), config).expect("open failed");

        println!("AFTER: Database opened with custom config");
        assert!(db.health_check().is_ok());
    }

    #[test]
    fn test_open_invalid_path_fails() {
        // Try to open in a non-existent path without create_if_missing
        let config = RocksDbConfig {
            create_if_missing: false,
            ..Default::default()
        };

        let result = RocksDbMemex::open_with_config("/nonexistent/path/db", config);
        assert!(result.is_err());

        if let Err(StorageError::OpenFailed { path, message }) = result {
            assert!(path.contains("nonexistent"));
            assert!(!message.is_empty());
        }
    }

    // =========================================================================
    // Column Family Tests
    // =========================================================================

    #[test]
    fn test_get_cf_returns_valid_handle() {
        let (_tmp, db) = create_temp_db();

        for cf_name in cf_names::ALL {
            let cf = db.get_cf(cf_name);
            assert!(cf.is_ok(), "CF '{}' should exist", cf_name);
        }
    }

    #[test]
    fn test_get_cf_unknown_returns_error() {
        let (_tmp, db) = create_temp_db();

        let result = db.get_cf("nonexistent_cf");
        assert!(result.is_err());

        if let Err(StorageError::ColumnFamilyNotFound { name }) = result {
            assert_eq!(name, "nonexistent_cf");
        } else {
            panic!("Expected ColumnFamilyNotFound error");
        }
    }

    #[test]
    fn test_all_12_cfs_accessible() {
        println!("=== TEST: All 12 column families accessible ===");
        let (_tmp, db) = create_temp_db();

        println!("BEFORE: Checking {} column families", cf_names::ALL.len());

        for (i, cf_name) in cf_names::ALL.iter().enumerate() {
            let cf = db.get_cf(cf_name).expect(&format!("CF {} should exist", cf_name));
            println!("  CF {}: '{}' -> handle obtained", i, cf_name);
            // CF handle is valid (non-null pointer internally)
            let _ = cf;
        }

        println!("AFTER: All 12 CFs verified accessible");
    }

    // =========================================================================
    // Health Check Tests
    // =========================================================================

    #[test]
    fn test_health_check_passes() {
        let (_tmp, db) = create_temp_db();
        let result = db.health_check();
        assert!(result.is_ok(), "Health check should pass: {:?}", result);
    }

    #[test]
    fn test_health_check_verifies_all_cfs() {
        println!("=== TEST: health_check verifies all CFs ===");
        let (_tmp, db) = create_temp_db();

        println!("BEFORE: Running health check");
        let result = db.health_check();
        println!("AFTER: Health check result = {:?}", result);

        assert!(result.is_ok());
    }

    // =========================================================================
    // Flush Tests
    // =========================================================================

    #[test]
    fn test_flush_all_succeeds() {
        let (_tmp, db) = create_temp_db();
        let result = db.flush_all();
        assert!(result.is_ok(), "Flush should succeed: {:?}", result);
    }

    #[test]
    fn test_flush_all_on_empty_db() {
        println!("=== TEST: flush_all on empty database ===");
        let (_tmp, db) = create_temp_db();

        println!("BEFORE: Flushing empty database");
        let result = db.flush_all();
        println!("AFTER: Flush result = {:?}", result);

        assert!(result.is_ok());
    }

    // =========================================================================
    // Reopen Tests
    // =========================================================================

    #[test]
    fn test_reopen_preserves_cfs() {
        println!("=== TEST: Reopen preserves column families ===");
        let tmp = TempDir::new().expect("create temp dir");
        let path = tmp.path().to_path_buf();

        // Open first time
        {
            println!("BEFORE: Opening database first time");
            let db = RocksDbMemex::open(&path).expect("first open failed");
            assert!(db.health_check().is_ok());
            println!("AFTER: First open successful, dropping database");
        } // db dropped here

        // Reopen
        {
            println!("BEFORE: Reopening database");
            let db = RocksDbMemex::open(&path).expect("reopen failed");
            println!("AFTER: Reopen successful");

            // Verify all CFs still exist
            for cf_name in cf_names::ALL {
                let cf = db.get_cf(cf_name);
                assert!(cf.is_ok(), "CF '{}' should exist after reopen", cf_name);
            }
            println!("RESULT: All 12 CFs preserved after reopen");
        }
    }

    // =========================================================================
    // Edge Case Tests (REQUIRED - print before/after state)
    // =========================================================================

    #[test]
    fn edge_case_multiple_opens_same_path_fails() {
        println!("=== EDGE CASE 1: Multiple opens on same path ===");
        let tmp = TempDir::new().expect("create temp dir");

        let db1 = RocksDbMemex::open(tmp.path()).expect("first open");
        println!("BEFORE: First database opened at {:?}", tmp.path());

        // Second open should fail (RocksDB lock)
        let result = RocksDbMemex::open(tmp.path());
        println!("AFTER: Second open attempt result = {:?}", result.is_err());

        assert!(result.is_err(), "Second open should fail due to lock");
        drop(db1);
        println!("RESULT: PASS - RocksDB prevents concurrent opens");
    }

    #[test]
    fn edge_case_minimum_cache_size() {
        println!("=== EDGE CASE 2: Minimum cache size (1MB) ===");
        let tmp = TempDir::new().expect("create temp dir");

        let config = RocksDbConfig {
            block_cache_size: 1024 * 1024, // 1MB
            ..Default::default()
        };

        println!("BEFORE: Opening with 1MB cache");
        let db = RocksDbMemex::open_with_config(tmp.path(), config).expect("open failed");
        println!("AFTER: Database opened with minimal cache");

        assert!(db.health_check().is_ok());
        println!("RESULT: PASS - Works with minimum cache");
    }

    #[test]
    fn edge_case_path_with_spaces() {
        println!("=== EDGE CASE 3: Path with spaces ===");
        let tmp = TempDir::new().expect("create temp dir");
        let path_with_spaces = tmp.path().join("path with spaces");
        std::fs::create_dir_all(&path_with_spaces).expect("create dir");

        println!("BEFORE: Opening at path with spaces: {:?}", path_with_spaces);
        let db = RocksDbMemex::open(&path_with_spaces).expect("open failed");
        println!("AFTER: Database opened successfully");

        assert!(db.health_check().is_ok());
        assert!(db.path().contains("path with spaces"));
        println!("RESULT: PASS - Path with spaces handled correctly");
    }

    // =========================================================================
    // db() accessor test
    // =========================================================================

    #[test]
    fn test_db_accessor() {
        let (_tmp, db) = create_temp_db();
        let raw_db = db.db();
        // Just verify we can access properties
        let path = raw_db.path();
        assert!(!path.to_string_lossy().is_empty());
    }

    // =========================================================================
    // Path accessor test
    // =========================================================================

    #[test]
    fn test_path_accessor() {
        let tmp = TempDir::new().expect("create temp dir");
        let expected_path = tmp.path().to_string_lossy().to_string();
        let db = RocksDbMemex::open(tmp.path()).expect("open failed");
        assert_eq!(db.path(), expected_path);
    }
}
```

---

## lib.rs Updates Required

Add these exports to `crates/context-graph-storage/src/lib.rs`:

```rust
// Re-export RocksDB backend types
pub use rocksdb_backend::{RocksDbConfig, RocksDbMemex, StorageError};
```

---

## Implementation Constraints

### MUST Follow
1. **Exactly 12 column families** - use `cf_names::ALL` (already defined)
2. **create_if_missing = true by default** - per specification
3. **max_open_files = 1000** - per constitution.yaml
4. **Block cache = 256MB** - per constitution.yaml
5. **WAL enabled by default** - durability requirement
6. **Database closes cleanly on drop** - RocksDB handles this automatically
7. **All errors must be descriptive** - include path/context for debugging

### MUST NOT Do
1. DO NOT use mock data in tests - use real tempdir + RocksDB
2. DO NOT create backwards compatibility shims
3. DO NOT add CRUD operations - those are in TASK-M02-017/018
4. DO NOT implement Memex trait - that's TASK-M02-026
5. DO NOT add features beyond specification

### NO BACKWARDS COMPATIBILITY
- If something doesn't work, it should error out immediately
- Robust error logging so failures are easy to debug
- No workarounds or fallbacks

---

## Verification Commands

```bash
# Build must succeed
cargo build --package context-graph-storage

# All tests must pass
cargo test --package context-graph-storage rocksdb_backend -- --nocapture

# Clippy must have 0 warnings
cargo clippy --package context-graph-storage -- -D warnings

# Run edge case tests specifically
cargo test --package context-graph-storage edge_case -- --nocapture
```

---

## Full State Verification Protocol

### 1. Source of Truth
The source of truth is:
- **RocksDB database files** on disk (in tempdir during tests)
- **Column family handles** accessible via `db.cf_handle()`

### 2. Execute & Inspect

After implementation, verify:
```bash
# Run all tests with output
cargo test --package context-graph-storage rocksdb_backend -- --nocapture 2>&1 | tee /tmp/rocksdb_test.log

# Verify key patterns in output
grep "test_open_creates_database.*ok" /tmp/rocksdb_test.log
grep "test_all_12_cfs_accessible.*ok" /tmp/rocksdb_test.log
grep "test_reopen_preserves_cfs.*ok" /tmp/rocksdb_test.log
```

### 3. Boundary & Edge Case Audit

The following 3 edge cases MUST be tested with before/after state printed:

| Edge Case | What to Test | Expected Result |
|-----------|--------------|-----------------|
| Multiple opens same path | Try to open DB twice on same path | Second open fails with lock error |
| Minimum cache size | Open with 1MB cache | DB opens and health check passes |
| Path with spaces | Open at path containing spaces | DB opens correctly |

### 4. Evidence of Success

Your test output MUST show:
```
=== TEST: open() creates database ===
BEFORE: Database path = ...
AFTER: Database opened successfully

=== TEST: All 12 column families accessible ===
BEFORE: Checking 12 column families
  CF 0: 'nodes' -> handle obtained
  CF 1: 'edges' -> handle obtained
  ...
AFTER: All 12 CFs verified accessible

=== EDGE CASE 1: Multiple opens on same path ===
BEFORE: First database opened at ...
AFTER: Second open attempt result = true (error)
RESULT: PASS - RocksDB prevents concurrent opens
```

---

## Definition of Done Checklist

- [ ] `RocksDbConfig` struct with 4 fields, Default impl
- [ ] `StorageError` enum with 5 variants
- [ ] `RocksDbMemex::open()` creates DB with all 12 CFs
- [ ] `RocksDbMemex::open_with_config()` accepts custom config
- [ ] `RocksDbMemex::get_cf()` returns valid CF handles
- [ ] `RocksDbMemex::path()` returns database path
- [ ] `RocksDbMemex::health_check()` verifies all 12 CFs
- [ ] `RocksDbMemex::flush_all()` flushes all CFs
- [ ] `RocksDbMemex::db()` returns raw DB reference
- [ ] Database closes cleanly on drop (no explicit impl needed)
- [ ] All unit tests pass (expect 15+ tests)
- [ ] Edge case tests print before/after state
- [ ] `cargo build --package context-graph-storage` succeeds
- [ ] `cargo clippy --package context-graph-storage` has 0 warnings
- [ ] lib.rs exports RocksDbConfig, RocksDbMemex, StorageError

---

## Final Verification Step (MANDATORY)

After completing all implementation and tests, you MUST spawn the `sherlock-holmes` subagent:

```
Use Task tool with subagent_type="sherlock-holmes" to:
1. Verify RocksDbMemex::open() creates database with all 12 CFs
2. Verify health_check() accesses all column families
3. Verify flush_all() succeeds
4. Verify reopen preserves column families
5. Run all tests and confirm 100% pass rate
6. Check for clippy warnings (must be 0)
7. Verify lib.rs exports are correct
8. Identify any discrepancies with specification
```

**If Sherlock identifies ANY issues, FIX THEM before marking task complete.**

---

*Task ID: TASK-M02-016*
*Module: 02 - Core Infrastructure*
*Layer: Logic*
*Last Updated: 2025-12-31*
*Dependencies: TASK-M02-014 ✅, TASK-M02-015 ✅*
