# M06-T03: Define PersistentMemoryStore Interface

```yaml
metadata:
  id: "M06-T03"
  title: "Define PersistentMemoryStore Interface"
  module: "module-06"
  module_name: "Stub Elimination"
  layer: "foundation"
  priority: "critical"
  estimated_hours: 3
  created: "2026-01-04"
  updated: "2026-01-04"
  status: "ready"
  dependencies: []
  spec_refs:
    - "constitution.yaml:30"         # db: { dev: sqlite, prod: postgres16+, vector: faiss_gpu }
    - "constitution.yaml:187-194"    # 5-Layer Bio-Nervous System
    - "contextprd.md:211-217"        # KnowledgeNode/GraphEdge schema
```

## CRITICAL CONTEXT FOR AI AGENT

**You are starting fresh. Read this entire document before coding.**

### What Already Exists (DO NOT RECREATE)

| Component | Location | Status |
|-----------|----------|--------|
| `MemoryStore` trait | `crates/context-graph-core/src/traits/memory_store.rs` | EXISTS - async trait with CRUD + search |
| `InMemoryStore` stub | `crates/context-graph-core/src/stubs/memory_stub.rs` | EXISTS - has cosine similarity ALREADY |
| `Memex` trait | `crates/context-graph-storage/src/memex.rs` | EXISTS - comprehensive RocksDB interface |
| `RocksDbMemex` impl | `crates/context-graph-storage/src/rocksdb_backend/` | EXISTS - production RocksDB backend |
| `SearchOptions` | `crates/context-graph-core/src/traits/memory_store.rs:9-43` | EXISTS - top_k, min_similarity, filters |

### What This Task ACTUALLY Needs to Do

The `MemoryStore` trait in `context-graph-core` is the **MCP handler interface**. The `Memex` trait in `context-graph-storage` is the **production storage interface**. These are TWO DIFFERENT ABSTRACTIONS serving different layers:

1. **`MemoryStore`** (core crate) - async, MCP-facing, simpler API
2. **`Memex`** (storage crate) - sync, RocksDB-specific, comprehensive API

**The task is to add missing persistence methods to `MemoryStore` trait so it can be implemented by a wrapper around `Memex`.**

---

## Problem Statement

The `MemoryStore` trait lacks persistence-oriented methods that are needed to properly wrap `Memex`:

| Missing in MemoryStore | Already in Memex |
|------------------------|------------------|
| `flush()` | N/A (RocksDB auto-syncs) |
| `checkpoint()` | N/A (manual backup) |
| `restore()` | N/A (manual restore) |
| `node_count()` (sync) | `health_check().node_count` |
| `storage_size_bytes()` | `health_check().storage_bytes` |
| `backend_type()` | N/A |

Additionally, `search_text()` in `InMemoryStore` returns hardcoded 0.5 similarity (line 117) because it cannot compute embeddings - this is acceptable for a stub but must be documented.

---

## Current State Analysis

### MemoryStore Trait (crates/context-graph-core/src/traits/memory_store.rs)

```rust
// Current methods (lines 63-101):
#[async_trait]
pub trait MemoryStore: Send + Sync {
    async fn store(&self, node: MemoryNode) -> CoreResult<NodeId>;
    async fn retrieve(&self, id: NodeId) -> CoreResult<Option<MemoryNode>>;
    async fn search(&self, query_embedding: &[f32], options: SearchOptions) -> CoreResult<Vec<(MemoryNode, f32)>>;
    async fn search_text(&self, query: &str, options: SearchOptions) -> CoreResult<Vec<(MemoryNode, f32)>>;
    async fn delete(&self, id: NodeId, soft: bool) -> CoreResult<bool>;
    async fn update(&self, node: MemoryNode) -> CoreResult<bool>;
    async fn count(&self) -> CoreResult<usize>;
    async fn compact(&self) -> CoreResult<()>;
}
```

### InMemoryStore Implementation (crates/context-graph-core/src/stubs/memory_stub.rs)

**CORRECT - Already implements cosine similarity:**
```rust
// Lines 29-43 - REAL cosine similarity, NOT hardcoded
fn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
    let dot: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm_a == 0.0 || norm_b == 0.0 { return 0.0; }
    dot / (norm_a * norm_b)
}

// Lines 60-104 - search() uses cosine_similarity correctly
async fn search(&self, query_embedding: &[f32], options: SearchOptions)
    -> CoreResult<Vec<(MemoryNode, f32)>> {
    // ... filters ...
    .map(|n| {
        let similarity = Self::cosine_similarity(query_embedding, &n.embedding);
        (n.clone(), similarity)
    })
    // ... sort by similarity descending ...
}
```

**KNOWN LIMITATION - search_text returns 0.5:**
```rust
// Lines 106-121 - Cannot compute embeddings, returns mock similarity
async fn search_text(&self, _query: &str, options: SearchOptions)
    -> CoreResult<Vec<(MemoryNode, f32)>> {
    // In stub, just return random nodes since we don't have real embeddings
    .map(|n| (n.clone(), 0.5)) // Mock similarity
}
```

---

## Scope

### In Scope

1. Add persistence methods to `MemoryStore` trait:
   - `async fn flush(&self) -> CoreResult<()>`
   - `async fn checkpoint(&self) -> CoreResult<PathBuf>`
   - `async fn restore(&self, checkpoint: &Path) -> CoreResult<()>`

2. Add statistics methods to `MemoryStore` trait:
   - `fn node_count_sync(&self) -> usize`
   - `fn storage_size_bytes(&self) -> usize`

3. Add `StorageBackend` enum and `StorageConfig` struct

4. Implement new methods in `InMemoryStore` (stub implementations)

5. Document `search_text` limitation in trait and stub

### Out of Scope

- Creating adapter from `Memex` to `MemoryStore` (M06-T05)
- Implementing RocksDB backend for MemoryStore (M06-T05)
- Fixing `search_text` to use real embeddings (requires EmbeddingProvider)
- The original task incorrectly said `InMemoryStore.search()` returns 0.5 - THIS IS FALSE, it computes real cosine similarity

---

## Definition of Done

### Required Changes

#### 1. Update MemoryStore Trait

**File:** `crates/context-graph-core/src/traits/memory_store.rs`

Add after line 101:

```rust
use std::path::{Path, PathBuf};

/// Storage backend type indicator.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum StorageBackend {
    /// In-memory storage (development/testing only)
    InMemory,
    /// SQLite file-based storage (development)
    SQLite,
    /// RocksDB embedded database (production)
    RocksDB,
    /// PostgreSQL with pgvector (production, distributed)
    PostgreSQL,
}

/// Configuration for storage backend selection.
#[derive(Debug, Clone)]
pub struct StorageConfig {
    /// Selected storage backend
    pub backend: StorageBackend,
    /// Path to storage (file path for SQLite/RocksDB, connection string for PostgreSQL)
    pub path: Option<PathBuf>,
    /// Cache size in megabytes
    pub cache_size_mb: usize,
    /// Whether to synchronize writes immediately
    pub sync_writes: bool,
}

impl Default for StorageConfig {
    fn default() -> Self {
        Self {
            backend: StorageBackend::InMemory,
            path: None,
            cache_size_mb: 64,
            sync_writes: false,
        }
    }
}

impl StorageConfig {
    /// Create configuration for RocksDB backend.
    pub fn rocksdb(path: impl Into<PathBuf>) -> Self {
        Self {
            backend: StorageBackend::RocksDB,
            path: Some(path.into()),
            cache_size_mb: 256,
            sync_writes: true,
        }
    }
}
```

Add to the trait (after `compact`):

```rust
    // =========================================================================
    // Persistence Operations
    // =========================================================================

    /// Flush any buffered writes to stable storage.
    ///
    /// For in-memory backends, this is a no-op.
    /// For disk-backed backends, ensures all writes are persisted.
    async fn flush(&self) -> CoreResult<()>;

    /// Create a checkpoint/snapshot for recovery.
    ///
    /// Returns the path to the checkpoint. For in-memory backends,
    /// may return an empty path or serialize to a temp file.
    ///
    /// # Returns
    /// Path to the checkpoint that can be used with `restore()`.
    async fn checkpoint(&self) -> CoreResult<PathBuf>;

    /// Restore from a previously created checkpoint.
    ///
    /// # Arguments
    /// * `checkpoint` - Path returned by a previous `checkpoint()` call
    async fn restore(&self, checkpoint: &Path) -> CoreResult<()>;

    // =========================================================================
    // Statistics (Sync for efficiency)
    // =========================================================================

    /// Get the current node count synchronously.
    ///
    /// This is a sync method for efficiency in hot paths.
    /// May return an approximate count for large stores.
    fn node_count_sync(&self) -> usize;

    /// Get the approximate storage size in bytes.
    ///
    /// For in-memory backends, returns estimated memory usage.
    /// For disk backends, returns actual disk usage.
    fn storage_size_bytes(&self) -> usize;

    /// Get the backend type this store uses.
    fn backend_type(&self) -> StorageBackend;
```

#### 2. Update InMemoryStore Implementation

**File:** `crates/context-graph-core/src/stubs/memory_stub.rs`

Add imports at top:

```rust
use std::path::{Path, PathBuf};
use crate::traits::StorageBackend;
```

Add implementations after `compact()`:

```rust
    async fn flush(&self) -> CoreResult<()> {
        // In-memory: no-op, all writes are immediately visible
        Ok(())
    }

    async fn checkpoint(&self) -> CoreResult<PathBuf> {
        // In-memory: serialize to temp file for testing
        use std::io::Write;

        let nodes = self.nodes.read().await;
        let data = serde_json::to_vec(&*nodes)
            .map_err(|e| crate::error::CoreError::Storage(e.to_string()))?;

        let path = std::env::temp_dir().join(format!(
            "inmemory_checkpoint_{}.json",
            chrono::Utc::now().timestamp_millis()
        ));

        std::fs::File::create(&path)
            .and_then(|mut f| f.write_all(&data))
            .map_err(|e| crate::error::CoreError::Storage(e.to_string()))?;

        Ok(path)
    }

    async fn restore(&self, checkpoint: &Path) -> CoreResult<()> {
        use std::io::Read;

        let mut data = Vec::new();
        std::fs::File::open(checkpoint)
            .and_then(|mut f| f.read_to_end(&mut data))
            .map_err(|e| crate::error::CoreError::Storage(e.to_string()))?;

        let restored: std::collections::HashMap<NodeId, MemoryNode> =
            serde_json::from_slice(&data)
                .map_err(|e| crate::error::CoreError::Storage(e.to_string()))?;

        let mut nodes = self.nodes.write().await;
        *nodes = restored;
        Ok(())
    }

    fn node_count_sync(&self) -> usize {
        // Use try_read for sync access - may undercount during writes
        self.nodes.try_read()
            .map(|n| n.values().filter(|n| !n.metadata.deleted).count())
            .unwrap_or(0)
    }

    fn storage_size_bytes(&self) -> usize {
        // Estimate: each node is roughly content_len + embedding_len * 4 + metadata
        self.nodes.try_read()
            .map(|nodes| {
                nodes.values().map(|n| {
                    n.content.len() + (n.embedding.len() * 4) + 256 // 256 for metadata
                }).sum()
            })
            .unwrap_or(0)
    }

    fn backend_type(&self) -> StorageBackend {
        StorageBackend::InMemory
    }
```

#### 3. Update mod.rs exports

**File:** `crates/context-graph-core/src/traits/mod.rs`

Change line 11 to:

```rust
pub use memory_store::{MemoryStore, SearchOptions, StorageBackend, StorageConfig};
```

---

## Verification Commands

```bash
# 1. Verify trait compiles with new methods
cargo check -p context-graph-core 2>&1 | head -50

# 2. Run existing InMemoryStore tests (should still pass)
cargo test -p context-graph-core memory_stub -- --nocapture

# 3. Verify cosine similarity is REAL (not 0.5)
cargo test -p context-graph-core test_cosine_similarity -- --nocapture

# 4. Verify search returns sorted results
cargo test -p context-graph-core test_memory_search_returns_correct_nodes -- --nocapture

# 5. Test new checkpoint/restore functionality
cargo test -p context-graph-core test_checkpoint_restore -- --nocapture
```

---

## Tests to Add

**File:** `crates/context-graph-core/src/stubs/memory_stub.rs` (in `#[cfg(test)]` module)

```rust
#[tokio::test]
async fn test_flush_is_noop() {
    let store = InMemoryStore::new();
    // Should complete without error
    store.flush().await.unwrap();
}

#[tokio::test]
async fn test_checkpoint_restore() {
    println!("=== CHECKPOINT RESTORE TEST ===");
    let store = InMemoryStore::new();

    // Store some nodes
    let embedding = vec![0.5; 1536];
    let node1 = MemoryNode::new("content 1".to_string(), embedding.clone());
    let node2 = MemoryNode::new("content 2".to_string(), embedding);
    let id1 = node1.id;
    let id2 = node2.id;

    store.store(node1).await.unwrap();
    store.store(node2).await.unwrap();

    println!("BEFORE CHECKPOINT: count = {}", store.count().await.unwrap());
    assert_eq!(store.count().await.unwrap(), 2);

    // Create checkpoint
    let checkpoint_path = store.checkpoint().await.unwrap();
    println!("CHECKPOINT PATH: {:?}", checkpoint_path);
    assert!(checkpoint_path.exists(), "Checkpoint file must exist");

    // Clear the store
    store.delete(id1, false).await.unwrap();
    store.delete(id2, false).await.unwrap();
    assert_eq!(store.count().await.unwrap(), 0, "Store should be empty after delete");

    // Restore from checkpoint
    store.restore(&checkpoint_path).await.unwrap();
    println!("AFTER RESTORE: count = {}", store.count().await.unwrap());

    // Verify restoration
    assert_eq!(store.count().await.unwrap(), 2, "Store should have 2 nodes after restore");
    assert!(store.retrieve(id1).await.unwrap().is_some(), "Node 1 should exist");
    assert!(store.retrieve(id2).await.unwrap().is_some(), "Node 2 should exist");

    // Cleanup
    std::fs::remove_file(checkpoint_path).ok();
    println!("RESULT: PASS - Checkpoint/restore works correctly");
}

#[tokio::test]
async fn test_node_count_sync() {
    let store = InMemoryStore::new();

    // Initially empty
    assert_eq!(store.node_count_sync(), 0);

    // Add nodes
    for i in 0..5 {
        let embedding = vec![i as f32 / 10.0; 1536];
        let node = MemoryNode::new(format!("content {}", i), embedding);
        store.store(node).await.unwrap();
    }

    assert_eq!(store.node_count_sync(), 5);
}

#[tokio::test]
async fn test_storage_size_bytes() {
    let store = InMemoryStore::new();

    // Initially minimal
    let initial_size = store.storage_size_bytes();
    assert_eq!(initial_size, 0);

    // Add a node
    let embedding = vec![0.1; 1536];
    let node = MemoryNode::new("test content".to_string(), embedding);
    store.store(node).await.unwrap();

    let size = store.storage_size_bytes();
    // Should be at least content (12) + embedding (1536 * 4) + metadata (256)
    assert!(size > 6000, "Size should be > 6KB, got {}", size);
}

#[tokio::test]
async fn test_backend_type() {
    let store = InMemoryStore::new();
    assert_eq!(store.backend_type(), StorageBackend::InMemory);
}
```

---

## Full State Verification Protocol

After completing the implementation, you MUST perform these verification steps:

### 1. Source of Truth Identification

- **Trait Definition:** `crates/context-graph-core/src/traits/memory_store.rs`
- **Stub Implementation:** `crates/context-graph-core/src/stubs/memory_stub.rs`
- **Test Outputs:** cargo test stdout

### 2. Execute & Inspect

```bash
# Run ALL tests and capture output
cargo test -p context-graph-core -- --nocapture 2>&1 | tee /tmp/m06-t03-test-output.txt

# Verify test count
grep -E "test result|passed|failed" /tmp/m06-t03-test-output.txt
```

### 3. Edge Case Verification

**Edge Case 1: Empty Store Checkpoint/Restore**
```bash
cargo test -p context-graph-core test_checkpoint_restore_empty_store -- --nocapture
```

**Edge Case 2: Checkpoint with 0-length content**
```bash
cargo test -p context-graph-core test_checkpoint_empty_content -- --nocapture
```

**Edge Case 3: Restore from non-existent path**
```bash
cargo test -p context-graph-core test_restore_invalid_path -- --nocapture
```

### 4. Evidence of Success

You MUST produce output showing:

```
=== M06-T03 VERIFICATION SUMMARY ===

1. TRAIT METHODS EXIST:
   grep -c "async fn flush" crates/context-graph-core/src/traits/memory_store.rs
   # Expected: 1

   grep -c "async fn checkpoint" crates/context-graph-core/src/traits/memory_store.rs
   # Expected: 1

   grep -c "async fn restore" crates/context-graph-core/src/traits/memory_store.rs
   # Expected: 1

   grep -c "fn node_count_sync" crates/context-graph-core/src/traits/memory_store.rs
   # Expected: 1

   grep -c "fn storage_size_bytes" crates/context-graph-core/src/traits/memory_store.rs
   # Expected: 1

   grep -c "fn backend_type" crates/context-graph-core/src/traits/memory_store.rs
   # Expected: 1

2. STUB IMPLEMENTS ALL METHODS:
   cargo build -p context-graph-core 2>&1 | grep -c "error"
   # Expected: 0

3. ALL TESTS PASS:
   cargo test -p context-graph-core memory_stub 2>&1 | grep "test result"
   # Expected: "test result: ok. X passed; 0 failed"

4. CHECKPOINT FILE ACTUALLY EXISTS:
   # From test output, verify checkpoint path exists during test execution

5. COSINE SIMILARITY IS COMPUTED (NOT HARDCODED):
   grep -A5 "fn cosine_similarity" crates/context-graph-core/src/stubs/memory_stub.rs
   # Expected: Shows actual dot product calculation
```

---

## Manual Verification Checklist

After implementation, manually verify:

- [ ] `cargo check -p context-graph-core` passes with no errors
- [ ] `cargo test -p context-graph-core` all tests pass
- [ ] `StorageBackend` enum is exported from `context_graph_core::traits`
- [ ] `StorageConfig` struct is exported from `context_graph_core::traits`
- [ ] `InMemoryStore` implements all new trait methods
- [ ] Checkpoint creates an actual file on disk
- [ ] Restore reads from that file and restores state
- [ ] `node_count_sync()` returns accurate count
- [ ] `storage_size_bytes()` returns non-zero for non-empty store

---

## SHERLOCK VERIFICATION (FINAL STEP)

After completing all implementation and tests, spawn the `sherlock-holmes` subagent to perform forensic verification:

```
Task: Verify M06-T03 implementation is complete and correct

Evidence Required:
1. All 6 new trait methods exist in memory_store.rs
2. InMemoryStore compiles and implements all trait methods
3. All tests pass with no failures
4. Checkpoint file is physically created during test
5. Restore actually modifies store state (verified by count change)
6. No regressions in existing tests

Investigation Steps:
1. Read memory_store.rs trait definition
2. Read memory_stub.rs implementation
3. Run cargo test and capture output
4. Verify checkpoint file existence
5. Report any discrepancies or issues
```

---

## Anti-Patterns to Avoid

- **AP-007 (constitution.yaml):** Do NOT use stub data in production
- Do NOT create mock implementations that hide failures
- Do NOT add backwards compatibility shims
- If a test would pass when the system is broken, the test is wrong
- If something fails, it should error with clear message, not silently return default

---

*Task updated: 2026-01-04*
*Module: 06 - Stub Elimination*
*Layer: Foundation*
*Priority: CRITICAL*
