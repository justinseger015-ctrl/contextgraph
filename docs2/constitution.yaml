# Context Graph Constitution v1.1.0 (Marblestone)
# Bio-Nervous MCP Server | UTL Knowledge System
# ═══════════════════════════════════════════════

meta:
  v: "1.1.0"
  spec: "2.1.0"
  name: "Ultimate Context Graph"
  desc: "5-layer bio-nervous UTL knowledge graph"
  updated: "2025-12-31"

# ═══════════════════════════════════════════════
# ABBREVIATIONS (used throughout)
# ═══════════════════════════════════════════════
# UTL=Unified Theory of Learning, L=Learning score
# ΔS=entropy change, ΔC=coherence change
# wₑ=emotional weight, φ=phase angle
# NT=neurotransmitter, SS=Steering Subsystem
# OI=Omnidirectional Inference, FV=Formal Verification
# PC=Predictive Coding, HE=Hyperbolic Entailment
# MHN=Modern Hopfield Network

# ═══════════════════════════════════════════════
# TECH STACK
# ═══════════════════════════════════════════════
stack:
  lang: { rust: "1.75+", edition: "2021", cuda: "13.1" }
  gpu: { target: "RTX 5090", vram: "32GB", compute: "12.0" }
  deps: [tokio@1.35+, serde@1.0+, uuid@1.6+, chrono@0.4+, rmcp@0.1+, cudarc@0.10+, faiss@0.12+gpu]
  db: { dev: sqlite, prod: postgres16+, vector: faiss_gpu, cache: redis7+ }
  embed_fallback: [openai/text-embedding-3-large, cohere/embed-english-v3.0]

# ═══════════════════════════════════════════════
# DIRECTORY STRUCTURE
# ═══════════════════════════════════════════════
dirs:
  crates/:
    context-graph-mcp/: "MCP server (tools/, resources/, handlers/)"
    context-graph-core/: "Domain logic (graph/, search/, utl/, session/, curation/)"
    context-graph-cuda/: "GPU (kernels/, faiss/, hopfield/, neuromod/)"
    context-graph-embeddings/: "12-model pipeline (models/, fusion/, fuse_moe.rs, came_ab.rs)"
  specs/: [functional/, technical/, tasks/]
  tests/: [integration/, benchmarks/, fixtures/, chaos/, validation/]
  config/: [default.toml, production.toml, test.toml]
  .ai/: [activeContext.md, decisionLog.md, progress.md]

# ═══════════════════════════════════════════════
# CODING STANDARDS
# ═══════════════════════════════════════════════
naming:
  files: { rust: snake_case.rs, cuda: snake_case.cu, tests: "{mod}_test.rs" }
  types: PascalCase  # structs, enums, traits
  funcs: snake_case_verb_first  # compute_learning_score()
  vars: { local: snake_case, const: SCREAMING_SNAKE }
  json: snake_case

rules:
  - "One primary type per module, max 500 lines (excl tests)"
  - "Co-locate unit tests via #[cfg(test)]"
  - "Import order: std → external → workspace (crate::) → super/self"
  - "Result<T,E> for fallible ops, thiserror for derivation"
  - "Never unwrap() in prod; use expect() with context"
  - "tokio async, Arc<RwLock<T>> for shared state"
  - "Lock order: inner → faiss_index (prevents deadlock)"
  - "Max 5 unsafe blocks/module, document safety invariants"
  - "CUDA FFI only in context-graph-cuda crate"

doc_format: "/// Brief\\n/// # Args/Returns/Errors/Examples/Panics\\n/// `Constraint: X < Yms`"

# ═══════════════════════════════════════════════
# ANTI-PATTERNS (FORBIDDEN)
# ═══════════════════════════════════════════════
forbidden:
  AP-001: "unwrap() in prod → use expect()"
  AP-002: "Hardcoded secrets → use env vars"
  AP-003: "Magic numbers → define constants"
  AP-004: "Blocking I/O in async → use tokio::fs/spawn_blocking"
  AP-005: "FAISS mutation without lock → acquire write lock"
  AP-006: "New util without checking utils/ → search first"
  AP-007: "Stub data in prod → use tests/fixtures/"
  AP-008: "Direct API from MCP handlers → use service layer"
  AP-009: "NaN/Infinity in UTL → clamp to valid range"
  AP-010: "store_memory without rationale → always required"
  AP-011: "merge_concepts without priors_vibe_check → check first"
  AP-012: "Trust distilled summaries → use hydrate_citation"
  AP-013: "Ignore Cognitive Pulse → check before next action"
  AP-014: "Permanent delete without user_requested → soft_delete default"
  AP-015: "GPU alloc without pool → use CUDA memory pool"

# ═══════════════════════════════════════════════
# SECURITY [SEC-##]
# ═══════════════════════════════════════════════
security:
  SEC-01: "Validate/sanitize all input (PIIScrubber L1)"
  SEC-02:
    rule: "Scrub PII pre-embed"
    patterns: [api_key, password, bearer_token, ssn, credit_card]
  SEC-03: { anomaly_threshold: "3.0 std", content_align_min: 0.4 }
  SEC-04:
    rule: "Detect prompt injection"
    patterns: ["ignore previous", "disregard system", "you are now", "new instructions:", "override:"]
  SEC-05: { rule: "Quarantine semantic cancer", trigger: "importance>0.9 AND neighbor_entropy>0.8", action: "reduce 50%, flag" }
  SEC-06: "Soft delete 30-day recovery (exception: user_requested+soft_delete=false)"
  SEC-07: "Secrets from env vars only"
  SEC-08: "No cross-agent memetic interference (perspective_lock)"

# ═══════════════════════════════════════════════
# PERFORMANCE BUDGETS
# ═══════════════════════════════════════════════
perf:
  latency:
    inject_context: { p95: "<25ms", p99: "<50ms" }
    hopfield: "<1ms"
    reflex_cache: "<100μs"
    single_embed: "<10ms"
    batch_embed_64: "<50ms"
    faiss_1M_k100: "<2ms"
    distillation: "<50ms"
    neuromod_update: "<200μs"
    dream_wake: "<100ms"
    entailment_check: "<1ms"
  throughput: { embed_batch: ">1000/sec", search_batch_100: "<5ms" }
  memory: { gpu: "<24GB (8GB headroom)", graph_cap: ">10M nodes" }
  quality:
    utl_avg: ">0.6"
    coherence_recovery: "<10s"
    attack_detection: ">95%"
    false_positive: "<2%"
    info_loss: "<15%"
    compression: ">60%"

# ═══════════════════════════════════════════════
# TESTING
# ═══════════════════════════════════════════════
testing:
  coverage: { unit: "90%", integration: "80%", docs: "80%" }
  types:
    unit: "Same file #[cfg(test)] - business logic, UTL, embedding"
    integration: "tests/integration/ - MCP, graph, session"
    benchmark: "benches/ - embed/search latency, throughput"
    chaos: "tests/chaos/ - GPU OOM, network partition, concurrent mutation"
    validation: "tests/validation/ - needle-haystack, UTL dynamics, dream effectiveness"
  gates:
    pre-commit: [fmt --check, clippy -D warnings, test --lib]
    pre-merge: [test --all, bench --no-run, "coverage>=90%"]
    pre-deploy: [integration pass, "bench regression<5%", chaos pass]

# ═══════════════════════════════════════════════
# UTL (Unified Theory of Learning)
# ═══════════════════════════════════════════════
utl:
  formula: "L = f((ΔS × ΔC) · wₑ · cos φ)"
  params:
    ΔS: "[0,1] entropy/novelty"
    ΔC: "[0,1] coherence/understanding"
    wₑ: "[0.5,1.5] emotional weight"
    φ: "[0,π] phase sync"
  loss: "J = 0.4·L_task + 0.3·L_semantic + 0.3·(1-L)"
  johari:
    Open: "ΔS<0.5, ΔC>0.5 → direct recall"
    Blind: "ΔS>0.5, ΔC<0.5 → discovery (epistemic_action/dream)"
    Hidden: "ΔS<0.5, ΔC<0.5 → private (get_neighborhood)"
    Unknown: "ΔS>0.5, ΔC>0.5 → frontier"
  lifecycle:  # Marblestone λ weights
    infancy:  { n: "0-50",   ΔS_trig: 0.9, ΔC_trig: 0.2, λ_ΔS: 0.7, λ_ΔC: 0.3, stance: "capture-novelty" }
    growth:   { n: "50-500", ΔS_trig: 0.7, ΔC_trig: 0.4, λ_ΔS: 0.5, λ_ΔC: 0.5, stance: "balanced" }
    maturity: { n: "500+",  ΔS_trig: 0.6, ΔC_trig: 0.5, λ_ΔS: 0.3, λ_ΔC: 0.7, stance: "curation-coherence" }

# ═══════════════════════════════════════════════
# GRAPH EDGE MODEL (Marblestone NT)
# ═══════════════════════════════════════════════
edge_model:
  attrs: [source:UUID, target:UUID, type:Semantic|Temporal|Causal|Hierarchical|Relational, weight:[0,1], confidence:[0,1]]
  nt_weights:
    formula: "w_eff = base × (1 + excitatory - inhibitory + 0.5×modulatory)"
    excitatory: "[0,1] strengthen"
    inhibitory: "[0,1] weaken"
    modulatory: "[0,1] domain-adjust"
    domain: Code|Legal|Medical|Creative|Research|General
  amortized:
    trigger: "3+ hop path traversed ≥5×"
    weight: "product(path_weights)"
    confidence: "≥0.7"
  steering_reward: "[-1,1]"

# ═══════════════════════════════════════════════
# 5-LAYER BIO-NERVOUS SYSTEM
# ═══════════════════════════════════════════════
layers:
  L1_Sensing: { latency: "<5ms", throughput: "10K/s", components: [12-model embed, PII scrub, adversarial detect], utl: "ΔS measurement" }
  L2_Reflex:  { latency: "<100μs", hit_rate: ">80%", components: [Hopfield cache], utl: "bypass if confidence>0.95" }
  L3_Memory:  { latency: "<1ms", capacity: "2^768 patterns", noise: ">20%", components: [MHN, FAISS GPU], utl: "consolidation" }
  L4_Learning: { freq: "100Hz", grad_clip: 1.0, components: [UTL optimizer, neuromod controller], utl: "L optimization" }
  L5_Coherence: { sync: "10ms", consistency: eventual, components: [Thalamic gate, PC, distiller, FV], utl: "φ sync" }

# ═══════════════════════════════════════════════
# NEUROMODULATION
# ═══════════════════════════════════════════════
neuromod:
  Dopamine:     { bio: "reward error", param: hopfield.beta, range: "[1,5]", effect: "↑=sharp retrieval" }
  Serotonin:    { bio: "temporal discount", param: fuse_moe.top_k, range: "[2,8]", effect: "↑=more experts" }
  Noradrenaline: { bio: "arousal/surprise", param: attention.temp, range: "[0.5,2]", effect: "↑=flat attention" }
  Acetylcholine: { bio: "learning rate", param: utl.lr, range: "[0.001,0.002]", effect: "↑=faster update" }

# ═══════════════════════════════════════════════
# DREAM LAYER
# ═══════════════════════════════════════════════
dream:
  trigger: { activity: "<0.15", idle: "10min" }
  phases:
    nrem: { dur: "3min", purpose: "replay recent", coupling: tight, recency_bias: 0.8 }
    rem:  { dur: "2min", purpose: "explore attractors", temp: 2.0 }
  constraints: { queries: 100, semantic_leap: 0.7, abort_on_query: true, wake: "<100ms", gpu: "<30%" }
  amortized: { trigger: "3+ hop ≥5×", weight: "product(path)", confidence: "≥0.7", is_shortcut: true }

# ═══════════════════════════════════════════════
# STEERING SUBSYSTEM (Marblestone)
# ═══════════════════════════════════════════════
steering:
  desc: "Reward signals only, no direct weight mod"
  components:
    Gardener: { role: "cross-session curation", trigger: "activity<0.15 for 2min" }
    Curator:  { auto: "dupes>0.95, weak<0.1, orphans>30d", escalate: "dupes 0.7-0.95, priors-incompatible, conflicts, semantic cancer" }
    Assessor: "per-interaction quality"
  reward: { range: "[-1,1]", fields: [reward, gardener_score, curator_score, assessor_score, explanation, suggestions] }
  dopamine: { pos: "+=r×0.2", neg: "-=|r|×0.1" }

# ═══════════════════════════════════════════════
# OMNIDIRECTIONAL INFERENCE (Marblestone)
# ═══════════════════════════════════════════════
omni_infer:
  directions:
    forward: "A→B prediction"
    backward: "B→A root cause"
    bidirectional: "A↔B discovery"
    bridge: "cross-domain"
    abduction: "best hypothesis"
  clamp: { hard: "fixed", soft: "biased adjustable" }
  active_inference: "EFE minimizes surprise+ambiguity"

# ═══════════════════════════════════════════════
# FORMAL VERIFICATION (Marblestone - L5)
# ═══════════════════════════════════════════════
formal_verify:
  desc: "Lean SMT for code nodes"
  location: L5_Coherence
  conditions: [bounds, null_safety, type_invariants, loop_termination, custom]
  status: [Verified, Failed, Timeout, NotApplicable]
  cache: content_hash
  timeout: "5s"
  latency: "<10ms cached"

# ═══════════════════════════════════════════════
# PREDICTIVE CODING
# ═══════════════════════════════════════════════
pred_coding:
  flow: "L5→L1: prediction→error(obs-pred)→propagate surprise only"
  reduction: "~30% tokens for predictable"
  domain_priors:
    medical: { causal: 1.8, code: 0.3 }
    programming: { code: 2.0, graph: 1.5 }
    creative: { semantic: 1.5, temporal: 0.5 }

# ═══════════════════════════════════════════════
# GRAPH GARDENER
# ═══════════════════════════════════════════════
gardener:
  trigger: "activity<0.15 for 2min"
  ops: ["prune weak edges (<0.1, no access)", "merge near-dupes (>0.95, priors ok)", "rebalance hyperbolic", "rebuild FAISS"]
  gpu: "<10%"

# ═══════════════════════════════════════════════
# PASSIVE CURATOR
# ═══════════════════════════════════════════════
curator:
  auto: { "dupes>0.95": merge, "weak<0.1": prune, "orphan>30d": review }
  escalate: { "dupes 0.7-0.95": curation_tasks, "priors-incompatible": curation_tasks, conflicts: conflict_alert, "semantic cancer": curation_tasks }
  efficiency: "~70% reduction"

# ═══════════════════════════════════════════════
# MCP PROTOCOL
# ═══════════════════════════════════════════════
mcp:
  version: "2024-11-05"
  transport: [stdio, sse]
  caps: [tools, resources, prompts, logging]
  errors:
    -32700: "Parse error"
    -32600: "Invalid Request"
    -32601: "Method not found"
    -32602: "Invalid params"
    -32603: "Internal error"
    -32000: "SessionNotFound"
    -32001: "GraphQueryError"
    -32002: "StorageError"
    -32003: "CausalInferenceError"
    -32004: "RateLimitExceeded"
  pulse: { fields: [entropy, coherence, suggested_action], cost: "~30 tokens" }
  marblestone_tools:
    get_steering_feedback: { params: "content,context,domain", returns: "SteeringReward" }
    omni_infer: { params: "start,direction,clamped", returns: "InferenceResult" }
    verify_code_node: { params: "node_id,conditions", returns: "VerificationResult" }

# ═══════════════════════════════════════════════
# 12-MODEL EMBEDDING
# ═══════════════════════════════════════════════
embeddings:
  models:
    E1_Semantic: { dim: 1024, math: Dense_Transformer, hw: TensorCore_FP8, lat: "<5ms" }
    E2_Temporal_Recent: { dim: 512, math: Exp_Decay, hw: VectorUnit, lat: "<2ms" }
    E3_Temporal_Periodic: { dim: 512, math: Fourier, hw: FFT, lat: "<2ms" }
    E4_Temporal_Positional: { dim: 512, math: Sin_PE, hw: CUDA, lat: "<2ms" }
    E5_Causal: { dim: 768, math: SCM_Intervention, hw: TensorCore, lat: "<8ms" }
    E6_Sparse: { dim: "~30K 5%active", math: TopK, hw: SparseTensor, lat: "<3ms" }
    E7_Code: { dim: 1536, math: AST_Transformer, hw: TensorCore_FP16, lat: "<10ms" }
    E8_Graph_GNN: { dim: 1536, math: MessagePassing, hw: CUDA_Graph, lat: "<5ms" }
    E9_HDC: { dim: "10K-bit", math: XOR_Hamming, hw: VectorUnit, lat: "<1ms" }
    E10_Multimodal: { dim: 1024, math: CrossAttention, hw: TensorCore, lat: "<15ms" }
    E11_Entity_TransE: { dim: 256, math: "h+r≈t", hw: CUDA, lat: "<2ms" }
    E12_LateInteraction: { dim: "128D/tok", math: ColBERT_MaxSim, hw: CUDA_Tile, lat: "<8ms" }
  fusion:
    fuse_moe: { top_k: 4, laplace_alpha: 0.01 }
    came_ab: { heads: 8, bridge_lr: 0.001 }

# ═══════════════════════════════════════════════
# VERBOSITY LEVELS
# ═══════════════════════════════════════════════
verbosity:
  0_RawOnly: { tokens: "~100", use: "high-confidence lookup" }
  1_TextAndIds: { tokens: "~200", use: "normal (DEFAULT)" }
  2_FullInsights: { tokens: "~800", use: "ONLY when ΔC<0.4", includes: [causal_links, entailment_cones, UTL, conflicts] }

# ═══════════════════════════════════════════════
# IMPLEMENTATION PHASES
# ═══════════════════════════════════════════════
phases:
  0_Ghost: { weeks: "2-4", delivers: "MCP interface, SQLite, external embed, mocked UTL, synthetic data" }
  1_Core: { weeks: 4 }
  2_Embedding: { weeks: 4 }
  3_Graph: { weeks: 4 }
  4_UTL: { weeks: 4 }
  5_BioNervous: { weeks: 4 }
  6_CUDA: { weeks: 3 }
  7_GDS: { weeks: 3 }
  8_Dream: { weeks: 3 }
  9_Neuromod: { weeks: 3 }
  10_Immune: { weeks: 3 }
  11_ActiveInference: { weeks: 2 }
  12_MCPHarden: { weeks: 4 }
  12.5_Marblestone: { weeks: 3, delivers: [SS, OI, FV, λ_weights, NT_edges, PC] }
  13_Test: { weeks: 4 }
  14_Deploy: { weeks: 4 }
  total: "~52 weeks"

# ═══════════════════════════════════════════════
# AGENT PROTOCOL
# ═══════════════════════════════════════════════
agent:
  session_start:
    - "Read .ai/activeContext.md, decisionLog.md, progress.md"
    - "Read constitution.yaml"
    - "Call get_graph_manifest, get_memetic_status"
    - "Call get_system_instructions → keep ~300 tok in context"
  mental_checks:
    "entropy>0.7 for 5min": trigger_dream
    "coherence<0.4": process curation_tasks
    "empty search": ↑noradrenaline, broaden
    "irrelevant search": reflect_on_memory
    "conflicting search": check conflict_alert, merge or ask
  curation_when: "suggested_action='curate'"
  session_end:
    - "Update .ai/activeContext.md, progress.md"
    - "Add decisions to decisionLog.md"

# ═══════════════════════════════════════════════
# REFERENCES
# ═══════════════════════════════════════════════
refs:
  internal: [vision_and_layers.md, technical_engine.md, execution_and_mcp.md, execution_and_mcp2.md, contextprd.md, implementationplan.md]
  external:
    - "NeuroDream: SSRN'25"
    - "SRC: NatComm"
    - "FEP: Wiki"
    - "ActiveInf: MIT"
    - "PC: Nature'25"
    - "Neuromod DNNs: TrendsNeuro"
    - "Homeostatic: eLife'25"
    - "HE Cones: ICML"
    - "Poincare: NeurIPS"
    - "UniGuardian: arXiv'25"
    - "OWASP LLM Top10"
    - "Marblestone AGI Arch: arXiv 2309.02427"
# END
