# M06-T08: Implement Real L2-L5 NervousLayers

```yaml
metadata:
  id: "M06-T08"
  title: "Implement Real L2-L5 NervousLayers"
  module: "module-06"
  module_name: "Stub Elimination"
  layer: "logic"
  priority: "medium"
  estimated_hours: 16
  created: "2026-01-04"
  status: "blocked"
  dependencies:
    - "M06-T07"  # SensingLayer (L1)
  spec_refs:
    - "constitution.yaml:191-194"  # L2-L5 specs
    - "contextprd.md:68-72"        # Layer descriptions
```

## Problem Statement

All 5 nervous system layers are stubs. After L1 (SensingLayer) is implemented in M06-T07, we need L2-L5.

## Context

From constitution.yaml:
- **L2 Reflex**: <100μs latency, >80% cache hit, Hopfield cache
- **L3 Memory**: <1ms latency, MHN + FAISS GPU, consolidation
- **L4 Learning**: 100Hz, UTL optimizer, neuromodulation
- **L5 Coherence**: 10ms sync, thalamic gate, predictive coding, FV

## Input Context Files

```
crates/context-graph-core/src/traits/nervous_layer.rs   # Layer trait
crates/context-graph-core/src/stubs/layers_stub.rs      # Stubs reference
crates/context-graph-core/src/layers/sensing.rs         # L1 from M06-T07
```

## Prerequisites

- [ ] M06-T07 complete (SensingLayer L1)
- [ ] Hopfield cache module exists or scaffolded
- [ ] UTL processor adapter exists (M06-T01)

## Scope

### In Scope

- Implement `ReflexLayer` (L2) with simple cache
- Implement `MemoryLayer` (L3) with storage integration
- Implement `LearningLayer` (L4) with UTL integration
- Implement `CoherenceLayer` (L5) with consistency checks
- Basic implementations that can be enhanced later

### Out of Scope

- Full Hopfield network (future optimization)
- Real predictive coding (future)
- Formal verification (future)
- Neuromodulation controller (future)

## Definition of Done

### Signatures

```rust
// File: crates/context-graph-core/src/layers/reflex.rs (L2)
pub struct ReflexLayer {
    cache: Arc<RwLock<LruCache<String, CachedResult>>>,
    config: ReflexConfig,
}

#[derive(Debug, Clone)]
pub struct ReflexConfig {
    pub cache_size: usize,
    pub confidence_threshold: f32,  // >0.95 for bypass
    pub ttl_seconds: u64,
}

#[async_trait]
impl NervousLayer for ReflexLayer {
    async fn process(&self, input: LayerInput) -> CoreResult<LayerOutput>;
    fn layer_id(&self) -> &str;  // "L2_Reflex"
    fn latency_budget_ms(&self) -> f64;  // 0.1 (100μs)
}

// File: crates/context-graph-core/src/layers/memory.rs (L3)
pub struct MemoryLayer {
    store: Arc<dyn MemoryStore>,
    index: Arc<dyn GraphIndex>,
    config: MemoryLayerConfig,
}

#[async_trait]
impl NervousLayer for MemoryLayer {
    async fn process(&self, input: LayerInput) -> CoreResult<LayerOutput>;
    fn layer_id(&self) -> &str;  // "L3_Memory"
    fn latency_budget_ms(&self) -> f64;  // 1.0
}

// File: crates/context-graph-core/src/layers/learning.rs (L4)
pub struct LearningLayer {
    utl_processor: Arc<dyn UtlProcessor>,
    config: LearningConfig,
}

#[async_trait]
impl NervousLayer for LearningLayer {
    async fn process(&self, input: LayerInput) -> CoreResult<LayerOutput>;
    fn layer_id(&self) -> &str;  // "L4_Learning"
    fn latency_budget_ms(&self) -> f64;  // 10.0
}

// File: crates/context-graph-core/src/layers/coherence.rs (L5)
pub struct CoherenceLayer {
    config: CoherenceConfig,
}

#[async_trait]
impl NervousLayer for CoherenceLayer {
    async fn process(&self, input: LayerInput) -> CoreResult<LayerOutput>;
    fn layer_id(&self) -> &str;  // "L5_Coherence"
    fn latency_budget_ms(&self) -> f64;  // 10.0
}
```

### Constraints

- L2: <100μs latency, LRU cache with TTL
- L3: <1ms latency, integrates with MemoryStore and GraphIndex
- L4: <10ms latency, integrates with UtlProcessor
- L5: <10ms latency, consistency validation
- All layers MUST be async-safe
- All layers MUST collect metrics

### Verification

```bash
# 1. Compile all layers
cargo build -p context-graph-core

# 2. Unit tests per layer
cargo test -p context-graph-core layers

# 3. Integration test of full pipeline
cargo test -p context-graph-core test_nervous_pipeline_l1_to_l5

# 4. Latency tests
cargo test -p context-graph-core test_all_layers_meet_latency_budgets
```

## Pseudo Code

```
ReflexLayer (L2):

  process(input):
    start = Instant::now()

    # Check cache
    cache_key = hash(input.content)
    if let Some(cached) = self.cache.read().get(&cache_key):
      if cached.confidence > self.config.confidence_threshold:
        return LayerOutput {
          data: cached.result.clone(),
          metrics: LayerMetrics { cache_hit: true, latency_ms: start.elapsed() },
        }

    # Cache miss - pass through
    return LayerOutput {
      data: input.data,
      metrics: LayerMetrics { cache_hit: false, latency_ms: start.elapsed() },
    }

  cache_result(key, result, confidence):
    self.cache.write().put(key, CachedResult { result, confidence, expires: now() + ttl })


MemoryLayer (L3):

  process(input):
    start = Instant::now()

    # Extract embedding from L1 output
    embedding = input.data.embedding

    # Search for similar memories
    similar = self.index.search(&embedding, top_k=10).await?

    # Retrieve full nodes
    nodes = []
    for result in similar:
      if let Some(node) = self.store.get(&result.id).await?:
        nodes.push((node, result.similarity))

    return LayerOutput {
      data: MemoryData {
        query_embedding: embedding,
        retrieved_nodes: nodes,
        retrieval_count: nodes.len(),
      },
      metrics: LayerMetrics { latency_ms: start.elapsed(), nodes_retrieved: nodes.len() },
    }


LearningLayer (L4):

  process(input):
    start = Instant::now()

    # Get context from L3 output
    context = input.data.retrieved_nodes

    # Compute UTL metrics
    utl_context = UtlContext {
      embedding: Some(input.data.query_embedding),
      context_embeddings: context.iter().map(|(n, _)| n.embedding.clone()).collect(),
    }

    metrics = self.utl_processor.compute_metrics(&input.content, &utl_context).await?

    return LayerOutput {
      data: LearningData {
        entropy: metrics.entropy,
        coherence: metrics.coherence,
        learning_score: metrics.learning_score,
        johari_quadrant: metrics.johari_quadrant,
      },
      metrics: LayerMetrics { latency_ms: start.elapsed() },
    }


CoherenceLayer (L5):

  process(input):
    start = Instant::now()

    # Validate coherence
    learning_data = input.data
    is_coherent = learning_data.coherence > self.config.coherence_threshold

    # Check for conflicts
    conflicts = detect_conflicts(input.retrieved_nodes)

    # Apply gating (thalamic filter)
    should_proceed = is_coherent && conflicts.is_empty()

    return LayerOutput {
      data: CoherenceData {
        is_coherent,
        conflicts,
        gated: should_proceed,
        suggested_action: determine_action(learning_data),
      },
      metrics: LayerMetrics { latency_ms: start.elapsed() },
    }
```

## Files to Create

| File | Description |
|------|-------------|
| `crates/context-graph-core/src/layers/reflex.rs` | L2 ReflexLayer |
| `crates/context-graph-core/src/layers/memory.rs` | L3 MemoryLayer |
| `crates/context-graph-core/src/layers/learning.rs` | L4 LearningLayer |
| `crates/context-graph-core/src/layers/coherence.rs` | L5 CoherenceLayer |
| `crates/context-graph-core/src/layers/pipeline.rs` | Full L1-L5 pipeline |

## Files to Modify

| File | Change |
|------|--------|
| `crates/context-graph-core/src/layers/mod.rs` | Export all layers |

## Validation Criteria

- [ ] All 4 layers (L2-L5) compile
- [ ] L2 cache hit/miss works correctly
- [ ] L3 retrieves real nodes from store
- [ ] L4 computes real UTL metrics
- [ ] L5 validates coherence
- [ ] Full pipeline L1→L5 works end-to-end
- [ ] All layers meet latency budgets

## Test Commands

```bash
# Run all layer tests
cargo test -p context-graph-core layers

# Pipeline test
cargo test -p context-graph-core test_nervous_pipeline

# Latency tests
cargo test -p context-graph-core test_layer_latencies
```

---

*Task created: 2026-01-04*
*Module: 06 - Stub Elimination*
*Layer: Logic*
*Priority: MEDIUM*
