# M06-T06: Implement FAISS GraphIndex

```yaml
metadata:
  id: "M06-T06"
  title: "Implement FAISS GraphIndex"
  module: "module-06"
  module_name: "Stub Elimination"
  layer: "logic"
  priority: "high"
  estimated_hours: 10
  created: "2026-01-04"
  status: "ready"
  dependencies: []
  spec_refs:
    - "constitution.yaml:117"       # faiss_1M_k100: <2ms
    - "constitution.yaml:123"       # graph_cap: >10M nodes
    - "contextprd.md:316-318"       # FAISS search targets
```

## Problem Statement

The `InMemoryGraphIndex` uses brute-force O(n) search and a no-op `rebuild()`. Real production requires FAISS for sub-millisecond similarity search at scale.

### Current State (BROKEN)

```rust
// stubs/graph_index_stub.rs
impl GraphIndex for InMemoryGraphIndex {
    async fn search(&self, query: &[f32], top_k: usize) -> CoreResult<Vec<IndexResult>> {
        // Brute force O(n) - unacceptable at scale
        let mut results: Vec<_> = self.embeddings.iter()
            .map(|(id, emb)| {
                let sim = cosine_similarity(query, emb);
                IndexResult { id: *id, similarity: sim }
            })
            .collect();
        results.sort_by(...);
        Ok(results.into_iter().take(top_k).collect())
    }

    async fn rebuild(&self) -> CoreResult<()> {
        // No-op - index never gets optimized
        Ok(())
    }
}
```

## Context

The `context-graph-cuda` crate has `FaissGpuIndex` but it's not connected to the core `GraphIndex` trait. This task creates the adapter.

## Input Context Files

```
crates/context-graph-core/src/traits/graph_index.rs     # Trait definition
crates/context-graph-cuda/src/faiss/                    # FAISS bindings
crates/context-graph-core/src/stubs/graph_index_stub.rs # Reference
```

## Prerequisites

- [ ] FAISS library installed (CPU or GPU variant)
- [ ] `context-graph-cuda` crate with FAISS bindings compiles

## Scope

### In Scope

- Create `FaissGraphIndex` implementing `GraphIndex` trait
- Support IVF+HNSW index type for fast search
- GPU acceleration when available, CPU fallback
- Incremental add/remove operations
- Index persistence (save/load)
- Automatic rebuild scheduling

### Out of Scope

- Multi-index sharding (future)
- Distributed FAISS (future)
- Custom quantization (future)

## Definition of Done

### Signatures

```rust
// File: crates/context-graph-core/src/index/faiss_index.rs
use crate::traits::{GraphIndex, IndexResult};
use context_graph_cuda::faiss::FaissIndex;

/// Configuration for FAISS index
#[derive(Debug, Clone)]
pub struct FaissConfig {
    pub dimensions: usize,
    pub index_type: FaissIndexType,
    pub nlist: usize,        // Number of clusters for IVF
    pub nprobe: usize,       // Number of clusters to search
    pub use_gpu: bool,
    pub persist_path: Option<PathBuf>,
}

#[derive(Debug, Clone)]
pub enum FaissIndexType {
    Flat,           // Exact search (small datasets)
    IvfFlat,        // Inverted file (medium)
    IvfPq,          // Product quantization (large)
    Hnsw,           // Hierarchical NSW (balanced)
}

/// FAISS-backed graph index for fast similarity search
pub struct FaissGraphIndex {
    index: FaissIndex,
    id_map: HashMap<i64, Uuid>,  // FAISS ID -> node UUID
    uuid_map: HashMap<Uuid, i64>, // node UUID -> FAISS ID
    config: FaissConfig,
    needs_rebuild: AtomicBool,
    pending_adds: RwLock<Vec<(Uuid, Vec<f32>)>>,
}

impl FaissGraphIndex {
    pub fn new(config: FaissConfig) -> Result<Self, IndexError>;
    pub fn load(path: impl AsRef<Path>) -> Result<Self, IndexError>;
    pub fn save(&self, path: impl AsRef<Path>) -> Result<(), IndexError>;
    pub fn train(&mut self, embeddings: &[Vec<f32>]) -> Result<(), IndexError>;
}

#[async_trait]
impl GraphIndex for FaissGraphIndex {
    async fn add(&self, id: Uuid, embedding: &[f32]) -> CoreResult<()>;
    async fn remove(&self, id: &Uuid) -> CoreResult<bool>;
    async fn search(&self, query: &[f32], top_k: usize) -> CoreResult<Vec<IndexResult>>;
    async fn rebuild(&self) -> CoreResult<()>;
    fn count(&self) -> usize;
    fn dimensions(&self) -> usize;
}
```

### Constraints

- Search latency: <2ms for 1M vectors, top-100
- MUST support incremental adds without full rebuild
- MUST handle concurrent search operations
- Rebuild should be async and non-blocking
- GPU memory usage must be bounded

### Verification

```bash
# 1. Compile with faiss feature
cargo build -p context-graph-core --features faiss

# 2. Unit tests
cargo test -p context-graph-core faiss_index

# 3. Benchmark
cargo bench -p context-graph-core faiss_search_latency

# 4. Verify sub-2ms search
cargo test -p context-graph-core test_faiss_search_under_2ms
```

## Pseudo Code

```
FaissGraphIndex:

  new(config):
    # Create index based on type
    index = match config.index_type:
      Flat => faiss::index_factory(dim, "Flat")
      IvfFlat => faiss::index_factory(dim, f"IVF{nlist},Flat")
      IvfPq => faiss::index_factory(dim, f"IVF{nlist},PQ32")
      Hnsw => faiss::index_factory(dim, "HNSW32")

    if config.use_gpu && cuda_available():
      index = faiss::index_cpu_to_gpu(index)

    return Self {
      index,
      id_map: HashMap::new(),
      uuid_map: HashMap::new(),
      config,
      needs_rebuild: AtomicBool::new(false),
      pending_adds: RwLock::new(vec![]),
    }

  async add(id, embedding):
    # Get next FAISS ID
    faiss_id = self.id_map.len() as i64

    # Add to index
    spawn_blocking(|| {
      self.index.add_with_ids(&[embedding], &[faiss_id])
    }).await?

    # Update maps
    self.id_map.insert(faiss_id, id)
    self.uuid_map.insert(id, faiss_id)

    # Mark for rebuild if needed
    if self.count() % 1000 == 0:
      self.needs_rebuild.store(true)

  async search(query, top_k):
    # Search FAISS
    (distances, indices) = spawn_blocking(|| {
      self.index.search(&[query], top_k)
    }).await?

    # Convert to IndexResults
    results = []
    for (dist, faiss_id) in zip(distances, indices):
      if faiss_id >= 0:  # -1 means not found
        if let Some(uuid) = self.id_map.get(&faiss_id):
          # Convert L2 distance to similarity
          similarity = 1.0 / (1.0 + dist)
          results.push(IndexResult { id: *uuid, similarity })

    return results

  async rebuild():
    # For IVF indices, retrain centroids
    if !self.index.is_trained:
      # Collect all embeddings
      embeddings = collect_all_embeddings()
      spawn_blocking(|| {
        self.index.train(&embeddings)
      }).await?

    self.needs_rebuild.store(false)
```

## Files to Create

| File | Description |
|------|-------------|
| `crates/context-graph-core/src/index/mod.rs` | Index module |
| `crates/context-graph-core/src/index/faiss_index.rs` | FAISS implementation |

## Files to Modify

| File | Change |
|------|--------|
| `crates/context-graph-core/src/lib.rs` | Add `pub mod index;` |
| `crates/context-graph-core/Cargo.toml` | Add FAISS feature flag |

## Validation Criteria

- [ ] Index creates without error
- [ ] Add/remove operations work correctly
- [ ] Search returns correct top-k results
- [ ] Search latency <2ms for 1M vectors
- [ ] Index persists and loads correctly
- [ ] Rebuild optimizes search performance
- [ ] GPU acceleration works when available

## Test Commands

```bash
# Run with faiss feature
cargo test -p context-graph-core --features faiss index

# Benchmark search
cargo bench -p context-graph-core --features faiss search

# Stress test
cargo test -p context-graph-core test_faiss_million_vectors --release
```

---

*Task created: 2026-01-04*
*Module: 06 - Stub Elimination*
*Layer: Logic*
*Priority: HIGH*
