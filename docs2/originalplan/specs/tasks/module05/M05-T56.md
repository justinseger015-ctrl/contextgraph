# M05-T56: Create API Documentation for Module 5 Public Types

## Task Metadata
- **ID**: M05-T56
- **Title**: Create API Documentation for Module 5 Public Types
- **Module**: 05 - UTL Integration
- **Layer**: completion
- **Priority**: medium
- **Estimated Hours**: 3
- **Created**: 2026-01-04
- **Status**: pending

## Description

Create comprehensive rustdoc documentation for all public UTL types.

Documentation requirements per constitution.yaml doc_format:
- Brief description
- `# Arguments` section
- `# Returns` section
- `# Errors` section
- `# Examples` with working code
- `# Panics` (if applicable)
- `Constraint: X < Yms` for performance-critical functions

Priority types:
- UtlProcessor, LearningSignal, UtlState
- LifecycleManager, LifecycleStage, LambdaWeights
- JohariClassifier, JohariQuadrant
- CognitivePulse

Generate doc coverage report (target: 80%).

## File Paths

### Implementation
- `crates/context-graph-utl/src/lib.rs`
- `crates/context-graph-utl/src/processor.rs`
- `crates/context-graph-utl/src/lifecycle/stage.rs`
- `crates/context-graph-utl/src/lifecycle/lambda.rs`
- `crates/context-graph-utl/src/lifecycle/manager.rs`
- `crates/context-graph-utl/src/johari/quadrant.rs`
- `crates/context-graph-utl/src/johari/classifier.rs`

### Tests
- None (documentation task)

## Dependencies

| Task ID | Title | Status |
|---------|-------|--------|
| M05-T22 | Implement UtlProcessor | pending |
| M05-T24 | Implement UtlMetrics and UtlStatus | pending |

## Acceptance Criteria

- [ ] All public types have rustdoc
- [ ] Examples compile and run
- [ ] Constraint annotations on hot paths
- [ ] Doc coverage >= 80%
- [ ] cargo doc generates without warnings

## Specification References

- `constitution.yaml doc_format`
- `constitution.yaml testing.coverage.docs`

## Implementation Notes

### Documentation Standards

Per constitution.yaml doc_format, all public items must follow this template:

```rust
/// Brief one-line description of the item.
///
/// Longer description with context and usage information.
/// Explain the "why" not just the "what".
///
/// # Arguments
///
/// * `arg1` - Description of first argument
/// * `arg2` - Description of second argument
///
/// # Returns
///
/// Description of return value and its meaning.
///
/// # Errors
///
/// * [`ErrorType::Variant`] - When this error occurs
/// * [`ErrorType::Other`] - When that error occurs
///
/// # Panics
///
/// Panics if [condition that causes panic].
///
/// # Examples
///
/// ```rust
/// use context_graph_utl::UtlProcessor;
///
/// let processor = UtlProcessor::new(config)?;
/// let signal = processor.compute(&context)?;
/// assert!(signal.learning_magnitude >= 0.0);
/// ```
///
/// # Performance
///
/// Constraint: < 10ms for full computation
///
/// # See Also
///
/// * [`RelatedType`] - For related functionality
```

### Priority Types Documentation

#### UtlProcessor (processor.rs)

```rust
//! UTL Processor - Core orchestrator for Unified Temporal Learning computation.
//!
//! The `UtlProcessor` is the main entry point for computing learning signals
//! based on the UTL formula defined in SPEC-UTL-005.
//!
//! # Overview
//!
//! The processor combines multiple components:
//! - Surprise calculation (KL divergence)
//! - Coherence tracking (semantic + structural)
//! - Emotional weighting
//! - Phase oscillation (consolidation cycles)
//! - Johari classification
//! - Lifecycle management (Marblestone)
//!
//! # Architecture
//!
//! ```text
//! Context → SurpriseCalculator → |
//!         → CoherenceTracker   → | → LearningSignal
//!         → EmotionalCalc      → |
//!         → PhaseOscillator    → |
//!         → JohariClassifier   → |
//!         → LifecycleManager   → |
//! ```
//!
//! # Examples
//!
//! ```rust
//! use context_graph_utl::{UtlProcessor, UtlConfig, UtlContext};
//!
//! // Create processor with default config
//! let config = UtlConfig::default();
//! let processor = UtlProcessor::new(config)?;
//!
//! // Compute learning signal for context
//! let context = UtlContext::builder()
//!     .embedding(vec![0.1; 1536])
//!     .content("New information")
//!     .build()?;
//!
//! let signal = processor.compute(&context)?;
//!
//! println!("Learning magnitude: {}", signal.learning_magnitude);
//! println!("Johari quadrant: {:?}", signal.johari_quadrant);
//! ```

/// Core UTL processor that orchestrates all computation components.
///
/// The processor is thread-safe and can be shared across async tasks.
/// It maintains internal state for coherence tracking and phase oscillation.
///
/// # Thread Safety
///
/// `UtlProcessor` is `Send + Sync` and uses internal synchronization
/// for mutable state (coherence window, phase).
///
/// # Performance
///
/// Constraint: Full computation < 10ms
/// - Surprise: < 5ms
/// - Coherence: < 5ms
/// - Other components: < 1ms each
///
/// # Examples
///
/// ```rust
/// use context_graph_utl::UtlProcessor;
/// use std::sync::Arc;
///
/// let processor = Arc::new(UtlProcessor::new(config)?);
///
/// // Use from multiple tasks
/// let p1 = processor.clone();
/// tokio::spawn(async move {
///     let signal = p1.compute(&context1).await?;
/// });
/// ```
pub struct UtlProcessor { /* ... */ }
```

#### LearningSignal

```rust
/// Learning signal output from UTL computation.
///
/// Contains all computed values from a single UTL processing pass.
/// This is the primary output type that drives downstream decisions
/// like retrieval strategy, distillation mode, and steering feedback.
///
/// # Fields Overview
///
/// | Field | Range | Description |
/// |-------|-------|-------------|
/// | `learning_magnitude` | [0.0, 1.0] | Overall learning importance |
/// | `surprise` | [0.0, 1.0] | Novelty/unexpectedness |
/// | `coherence` | [0.0, 1.0] | Consistency with context |
/// | `emotional_weight` | [0.5, 1.5] | Emotional modulation |
/// | `phase_modulation` | [0.5, 1.5] | Consolidation phase effect |
///
/// # Examples
///
/// ```rust
/// use context_graph_utl::LearningSignal;
///
/// let signal = processor.compute(&context)?;
///
/// // High learning = novel and coherent
/// if signal.learning_magnitude > 0.7 {
///     prioritize_for_storage(&signal);
/// }
///
/// // Check Johari quadrant for strategy
/// match signal.johari_quadrant {
///     JohariQuadrant::Open => use_shallow_search(),
///     JohariQuadrant::Unknown => use_deep_search(),
///     _ => use_standard_search(),
/// }
/// ```
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LearningSignal {
    /// Primary learning magnitude L in [0.0, 1.0].
    ///
    /// Computed as: L = S * (1 - C) * E * P * lambda_weights
    /// where S=surprise, C=coherence, E=emotional, P=phase
    pub learning_magnitude: f32,

    /// Surprise component in [0.0, 1.0].
    ///
    /// High values indicate novel/unexpected content.
    /// Computed via KL divergence from prior distribution.
    pub surprise: f32,

    /// Coherence component in [0.0, 1.0].
    ///
    /// High values indicate consistency with recent context.
    /// Combines semantic and structural coherence.
    pub coherence: f32,

    /// Emotional weight modulation in [0.5, 1.5].
    ///
    /// > 1.0 amplifies learning for emotional content.
    /// < 1.0 dampens learning for neutral content.
    pub emotional_weight: f32,

    /// Phase oscillator modulation in [0.5, 1.5].
    ///
    /// Encoding phase (> 1.0): Emphasize novelty
    /// Consolidation phase (< 1.0): Emphasize coherence
    pub phase_modulation: f32,

    /// Johari window quadrant classification.
    ///
    /// Drives retrieval strategy and verbosity.
    pub johari_quadrant: JohariQuadrant,

    /// Lifecycle lambda weights applied.
    ///
    /// Changes based on Marblestone lifecycle stage.
    pub lambda_weights: LambdaWeights,

    /// Suggested action based on UTL state.
    ///
    /// Optional recommendation for agent behavior.
    pub suggested_action: Option<SuggestedAction>,

    /// Computation timestamp.
    pub computed_at: DateTime<Utc>,

    /// Computation latency in microseconds.
    pub latency_us: u64,
}
```

#### LifecycleStage

```rust
/// Marblestone lifecycle stage for developmental learning.
///
/// Based on the Marblestone et al. framework for AI development,
/// the lifecycle tracks the system's learning maturity through
/// three distinct stages with different learning priorities.
///
/// # Stage Progression
///
/// ```text
/// Infancy (0-50) → Growth (50-500) → Maturity (500+)
///   λ_n=0.7          λ_n=0.5           λ_n=0.3
///   λ_c=0.3          λ_c=0.5           λ_c=0.7
/// ```
///
/// # Lambda Weight Invariant
///
/// At all stages: `lambda_novelty + lambda_consolidation = 1.0`
///
/// # Examples
///
/// ```rust
/// use context_graph_utl::LifecycleStage;
///
/// let stage = LifecycleStage::from_interaction_count(75);
/// assert_eq!(stage, LifecycleStage::Growth);
///
/// let weights = stage.default_weights();
/// assert_eq!(weights.lambda_novelty, 0.5);
/// assert_eq!(weights.lambda_consolidation, 0.5);
/// ```
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum LifecycleStage {
    /// Early development: Prioritize novelty acquisition.
    ///
    /// - Interaction count: 0-49
    /// - Lambda weights: novelty=0.7, consolidation=0.3
    /// - Focus: Explore, acquire new knowledge
    Infancy,

    /// Balanced development: Equal novelty and consolidation.
    ///
    /// - Interaction count: 50-499
    /// - Lambda weights: novelty=0.5, consolidation=0.5
    /// - Focus: Balance exploration and integration
    Growth,

    /// Mature system: Prioritize knowledge consolidation.
    ///
    /// - Interaction count: 500+
    /// - Lambda weights: novelty=0.3, consolidation=0.7
    /// - Focus: Integrate, consolidate, refine
    Maturity,
}
```

#### JohariQuadrant

```rust
/// Johari window quadrant for metacognitive classification.
///
/// Based on the Johari Window model adapted for AI self-awareness,
/// classifies knowledge states along two dimensions:
/// - Self-awareness (agent knows)
/// - External observability (others know)
///
/// # Quadrant Truth Table
///
/// | Confidence | Freshness | Quadrant |
/// |------------|-----------|----------|
/// | High (>θ)  | Fresh     | Open     |
/// | High (>θ)  | Stale     | Hidden   |
/// | Low (≤θ)   | Fresh     | Blind    |
/// | Low (≤θ)   | Stale     | Unknown  |
///
/// Where θ = confidence_threshold (default 0.6)
///
/// # Retrieval Strategy Mapping
///
/// | Quadrant | Strategy | Depth | Description |
/// |----------|----------|-------|-------------|
/// | Open     | Shallow  | 1-2   | Known, use directly |
/// | Blind    | Broad    | 2-3   | Uncertain, explore |
/// | Hidden   | Recent   | 1-2   | Stale, refresh |
/// | Unknown  | Deep     | 3+    | Novel, investigate |
///
/// # Examples
///
/// ```rust
/// use context_graph_utl::{JohariQuadrant, JohariClassifier};
///
/// let classifier = JohariClassifier::new(0.6);
/// let quadrant = classifier.classify(confidence, freshness);
///
/// let strategy = match quadrant {
///     JohariQuadrant::Open => RetrievalStrategy::shallow(2),
///     JohariQuadrant::Unknown => RetrievalStrategy::deep(5),
///     _ => RetrievalStrategy::standard(3),
/// };
/// ```
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum JohariQuadrant {
    /// High confidence, fresh knowledge.
    ///
    /// Agent knows and information is current.
    /// Use directly with high trust.
    Open,

    /// Low confidence, fresh knowledge.
    ///
    /// Agent uncertain about recent information.
    /// Explore broadly to reduce uncertainty.
    Blind,

    /// High confidence, stale knowledge.
    ///
    /// Agent knows but information may be outdated.
    /// Focus on refreshing temporal context.
    Hidden,

    /// Low confidence, stale knowledge.
    ///
    /// Agent uncertain about old information.
    /// Deep investigation needed.
    Unknown,
}
```

### Documentation Coverage Verification

```bash
# Generate documentation with coverage stats
RUSTDOCFLAGS="--cfg doc_cfg" cargo doc --no-deps -p context-graph-utl

# Check for missing documentation
cargo doc --no-deps -p context-graph-utl 2>&1 | grep -c "warning: missing documentation"

# Generate coverage report (requires cargo-llvm-cov or similar)
cargo llvm-cov --html -- --lib -p context-graph-utl
```

### Example Validation

All examples must compile and run:

```bash
# Test doc examples
cargo test --doc -p context-graph-utl

# Verify examples with strict mode
RUSTDOCFLAGS="-D warnings" cargo doc --no-deps -p context-graph-utl
```

### Performance Constraint Annotations

For performance-critical functions, add constraint annotations:

```rust
/// Compute learning magnitude from context.
///
/// # Performance
///
/// Constraint: < 10ms for 1536-dimensional embeddings with 50 context entries.
///
/// | Component | Target | P99 |
/// |-----------|--------|-----|
/// | Surprise  | < 5ms  | < 20ms |
/// | Coherence | < 5ms  | < 25ms |
/// | Total     | < 10ms | < 50ms |
pub fn compute(&self, context: &UtlContext) -> Result<LearningSignal, UtlError>
```

## Testing Requirements

1. **Documentation Build**
   - `cargo doc --no-deps` succeeds without warnings
   - All internal links resolve correctly
   - Module-level documentation present

2. **Example Validation**
   - All `# Examples` code blocks compile
   - Examples produce expected output
   - No panics in example code

3. **Coverage Metrics**
   - >= 80% of public items documented
   - All public structs have field docs
   - All public functions have argument docs

4. **Cross-Reference Validation**
   - `# See Also` links are valid
   - Specification references are accurate
   - No broken internal links

---

*Task specification generated for Module 05 - UTL Integration*
