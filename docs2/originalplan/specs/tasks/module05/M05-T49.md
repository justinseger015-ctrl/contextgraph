# M05-T49: Implement UTL Composite Loss Function

## Task Metadata
- **ID**: M05-T49
- **Title**: Implement UTL Composite Loss Function
- **Module**: 05 - UTL Integration
- **Layer**: completion
- **Priority**: medium
- **Estimated Hours**: 2.5

## Description

Implement the composite loss function as defined in constitution.yaml.

Formula: J = 0.4·L_task + 0.3·L_semantic + 0.3·(1-L)

Where:
- L_task: Task-specific loss (retrieval relevance)
- L_semantic: Semantic similarity loss
- L: Learning magnitude from UTL

Create ComputeLoss trait with compute_loss(predictions, targets, utl_state).
Integrate with neuromodulation feedback loop (acetylcholine modulation).
Store loss history for gradient analysis.

Note: Active training happens in Module 10; this provides the interface.

## File Path
`crates/context-graph-utl/src/loss.rs`

## Dependencies
- M05-T20: Core UTL learning magnitude
- M05-T21: LearningSignal and UtlState

## Acceptance Criteria
- [ ] compute_composite_loss() implements J formula
- [ ] Loss components individually accessible
- [ ] Loss history tracking implemented
- [ ] Interface compatible with gradient-based optimization
- [ ] ComputeLoss trait defined for extensibility

## Test File
`crates/context-graph-utl/tests/loss_tests.rs`

## Specification References
- constitution.yaml utl.loss

## Implementation Notes

### Configuration

```rust
use serde::{Deserialize, Serialize};

/// Configuration for composite loss function
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LossConfig {
    /// Weight for task-specific loss (default: 0.4)
    #[serde(default = "default_task_weight")]
    pub lambda_task: f32,

    /// Weight for semantic similarity loss (default: 0.3)
    #[serde(default = "default_semantic_weight")]
    pub lambda_semantic: f32,

    /// Weight for learning magnitude component (default: 0.3)
    #[serde(default = "default_learning_weight")]
    pub lambda_learning: f32,

    /// Maximum history length for gradient analysis
    #[serde(default = "default_history_length")]
    pub history_max_length: usize,

    /// Enable neuromodulation feedback
    #[serde(default)]
    pub enable_neuromod_feedback: bool,
}

fn default_task_weight() -> f32 { 0.4 }
fn default_semantic_weight() -> f32 { 0.3 }
fn default_learning_weight() -> f32 { 0.3 }
fn default_history_length() -> usize { 1000 }

impl Default for LossConfig {
    fn default() -> Self {
        Self {
            lambda_task: default_task_weight(),
            lambda_semantic: default_semantic_weight(),
            lambda_learning: default_learning_weight(),
            history_max_length: default_history_length(),
            enable_neuromod_feedback: false,
        }
    }
}

impl LossConfig {
    /// Validate that weights sum to 1.0
    pub fn validate(&self) -> Result<(), LossError> {
        let sum = self.lambda_task + self.lambda_semantic + self.lambda_learning;
        if (sum - 1.0).abs() > 0.001 {
            return Err(LossError::InvalidWeights {
                sum,
                expected: 1.0,
            });
        }
        Ok(())
    }
}
```

### Core Types

```rust
use std::collections::VecDeque;

/// Components of the composite loss
#[derive(Debug, Clone, Default)]
pub struct LossComponents {
    /// Task-specific loss (retrieval relevance)
    pub task_loss: f32,

    /// Semantic similarity loss
    pub semantic_loss: f32,

    /// Learning-based loss component (1 - L)
    pub learning_loss: f32,

    /// The combined composite loss J
    pub composite_loss: f32,
}

impl LossComponents {
    /// Check if all components are valid (not NaN or Infinity)
    pub fn is_valid(&self) -> bool {
        [self.task_loss, self.semantic_loss, self.learning_loss, self.composite_loss]
            .iter()
            .all(|v| v.is_finite())
    }
}

/// A single entry in loss history
#[derive(Debug, Clone)]
pub struct LossHistoryEntry {
    pub timestamp: std::time::SystemTime,
    pub components: LossComponents,
    pub context_size: usize,
    pub lifecycle_stage: LifecycleStage,
}

/// Result of gradient analysis on loss history
#[derive(Debug, Clone, Default)]
pub struct LossGradient {
    /// Rate of change for composite loss
    pub composite_gradient: f32,

    /// Rate of change for each component
    pub task_gradient: f32,
    pub semantic_gradient: f32,
    pub learning_gradient: f32,

    /// Moving average of composite loss
    pub moving_average: f32,

    /// Variance in recent losses
    pub variance: f32,
}

/// Errors related to loss computation
#[derive(Debug, thiserror::Error)]
pub enum LossError {
    #[error("Invalid weights: sum is {sum}, expected {expected}")]
    InvalidWeights { sum: f32, expected: f32 },

    #[error("Invalid input: {reason}")]
    InvalidInput { reason: String },

    #[error("Computation resulted in NaN or Infinity")]
    InvalidComputation,
}
```

### ComputeLoss Trait

```rust
use crate::{LearningSignal, UtlState};

/// Trait for computing loss functions
///
/// This trait defines the interface for loss computation,
/// allowing different implementations for different tasks.
pub trait ComputeLoss {
    /// Compute the composite loss
    ///
    /// # Arguments
    /// * `predictions` - Model predictions (e.g., retrieved embeddings)
    /// * `targets` - Ground truth targets
    /// * `utl_state` - Current UTL state for learning magnitude
    ///
    /// # Returns
    /// The computed loss components
    fn compute_loss(
        &self,
        predictions: &[f32],
        targets: &[f32],
        utl_state: &UtlState,
    ) -> Result<LossComponents, LossError>;

    /// Compute just the task-specific loss
    fn compute_task_loss(
        &self,
        predictions: &[f32],
        targets: &[f32],
    ) -> Result<f32, LossError>;

    /// Compute just the semantic similarity loss
    fn compute_semantic_loss(
        &self,
        predictions: &[f32],
        targets: &[f32],
    ) -> Result<f32, LossError>;
}
```

### Main Implementation

```rust
/// Composite loss function as defined in constitution.yaml
///
/// Formula: J = λ_task·L_task + λ_semantic·L_semantic + λ_learning·(1-L)
///
/// Default weights: 0.4, 0.3, 0.3
pub struct CompositeLoss {
    config: LossConfig,
    history: VecDeque<LossHistoryEntry>,
}

impl CompositeLoss {
    pub fn new(config: LossConfig) -> Result<Self, LossError> {
        config.validate()?;
        Ok(Self {
            config,
            history: VecDeque::with_capacity(config.history_max_length),
        })
    }

    /// Compute the composite loss with all components
    pub fn compute(
        &mut self,
        predictions: &[f32],
        targets: &[f32],
        learning_signal: &LearningSignal,
        lifecycle_stage: &LifecycleStage,
    ) -> Result<LossComponents, LossError> {
        // Validate inputs
        if predictions.len() != targets.len() {
            return Err(LossError::InvalidInput {
                reason: "predictions and targets must have same length".into(),
            });
        }

        // Compute individual components
        let task_loss = self.compute_task_loss_internal(predictions, targets)?;
        let semantic_loss = self.compute_semantic_loss_internal(predictions, targets)?;
        let learning_loss = 1.0 - learning_signal.learning_magnitude.clamp(0.0, 1.0);

        // Compute composite: J = 0.4·L_task + 0.3·L_semantic + 0.3·(1-L)
        let composite_loss =
            self.config.lambda_task * task_loss +
            self.config.lambda_semantic * semantic_loss +
            self.config.lambda_learning * learning_loss;

        let components = LossComponents {
            task_loss,
            semantic_loss,
            learning_loss,
            composite_loss: composite_loss.clamp(0.0, 1.0),
        };

        // Validate output
        if !components.is_valid() {
            return Err(LossError::InvalidComputation);
        }

        // Record history
        self.record_history(&components, predictions.len(), lifecycle_stage);

        Ok(components)
    }

    /// Compute task-specific loss (retrieval relevance)
    ///
    /// Uses mean squared error between predictions and targets
    fn compute_task_loss_internal(
        &self,
        predictions: &[f32],
        targets: &[f32],
    ) -> Result<f32, LossError> {
        if predictions.is_empty() {
            return Ok(0.0);
        }

        let mse: f32 = predictions.iter()
            .zip(targets.iter())
            .map(|(p, t)| (p - t).powi(2))
            .sum::<f32>() / predictions.len() as f32;

        if !mse.is_finite() {
            return Err(LossError::InvalidComputation);
        }

        Ok(mse.clamp(0.0, 1.0))
    }

    /// Compute semantic similarity loss
    ///
    /// Uses 1 - cosine similarity
    fn compute_semantic_loss_internal(
        &self,
        predictions: &[f32],
        targets: &[f32],
    ) -> Result<f32, LossError> {
        if predictions.is_empty() {
            return Ok(0.0);
        }

        let dot: f32 = predictions.iter()
            .zip(targets.iter())
            .map(|(p, t)| p * t)
            .sum();

        let pred_norm: f32 = predictions.iter().map(|x| x * x).sum::<f32>().sqrt();
        let target_norm: f32 = targets.iter().map(|x| x * x).sum::<f32>().sqrt();

        if pred_norm == 0.0 || target_norm == 0.0 {
            return Ok(1.0); // Maximum dissimilarity
        }

        let cosine_sim = dot / (pred_norm * target_norm);
        let loss = 1.0 - cosine_sim.clamp(-1.0, 1.0);

        if !loss.is_finite() {
            return Err(LossError::InvalidComputation);
        }

        Ok(loss.clamp(0.0, 2.0) / 2.0) // Normalize to [0, 1]
    }

    /// Record loss entry to history
    fn record_history(
        &mut self,
        components: &LossComponents,
        context_size: usize,
        lifecycle_stage: &LifecycleStage,
    ) {
        let entry = LossHistoryEntry {
            timestamp: std::time::SystemTime::now(),
            components: components.clone(),
            context_size,
            lifecycle_stage: lifecycle_stage.clone(),
        };

        self.history.push_back(entry);

        // Maintain max history length
        while self.history.len() > self.config.history_max_length {
            self.history.pop_front();
        }
    }

    /// Analyze gradient from loss history
    ///
    /// Useful for understanding training dynamics
    pub fn analyze_gradient(&self, window_size: usize) -> LossGradient {
        if self.history.len() < 2 {
            return LossGradient::default();
        }

        let window: Vec<_> = self.history.iter()
            .rev()
            .take(window_size)
            .collect();

        if window.len() < 2 {
            return LossGradient::default();
        }

        // Compute gradients (simple finite differences)
        let n = window.len() as f32;

        let composite_values: Vec<f32> = window.iter()
            .map(|e| e.components.composite_loss)
            .collect();

        let moving_average = composite_values.iter().sum::<f32>() / n;

        let variance = composite_values.iter()
            .map(|v| (v - moving_average).powi(2))
            .sum::<f32>() / n;

        // Gradient approximation (first - last) / n
        let composite_gradient = (window.first().unwrap().components.composite_loss
            - window.last().unwrap().components.composite_loss) / n;

        LossGradient {
            composite_gradient,
            task_gradient: 0.0, // TODO: implement per-component gradients
            semantic_gradient: 0.0,
            learning_gradient: 0.0,
            moving_average,
            variance,
        }
    }

    /// Get recent loss history
    pub fn history(&self) -> &VecDeque<LossHistoryEntry> {
        &self.history
    }

    /// Clear loss history
    pub fn clear_history(&mut self) {
        self.history.clear();
    }

    /// Get average loss over recent history
    pub fn recent_average(&self, n: usize) -> f32 {
        let recent: Vec<f32> = self.history.iter()
            .rev()
            .take(n)
            .map(|e| e.components.composite_loss)
            .collect();

        if recent.is_empty() {
            return 0.0;
        }

        recent.iter().sum::<f32>() / recent.len() as f32
    }
}

impl ComputeLoss for CompositeLoss {
    fn compute_loss(
        &self,
        predictions: &[f32],
        targets: &[f32],
        utl_state: &UtlState,
    ) -> Result<LossComponents, LossError> {
        let task_loss = self.compute_task_loss(predictions, targets)?;
        let semantic_loss = self.compute_semantic_loss(predictions, targets)?;
        let learning_loss = 1.0 - utl_state.learning_magnitude.clamp(0.0, 1.0);

        let composite_loss =
            self.config.lambda_task * task_loss +
            self.config.lambda_semantic * semantic_loss +
            self.config.lambda_learning * learning_loss;

        Ok(LossComponents {
            task_loss,
            semantic_loss,
            learning_loss,
            composite_loss: composite_loss.clamp(0.0, 1.0),
        })
    }

    fn compute_task_loss(
        &self,
        predictions: &[f32],
        targets: &[f32],
    ) -> Result<f32, LossError> {
        self.compute_task_loss_internal(predictions, targets)
    }

    fn compute_semantic_loss(
        &self,
        predictions: &[f32],
        targets: &[f32],
    ) -> Result<f32, LossError> {
        self.compute_semantic_loss_internal(predictions, targets)
    }
}
```

### Neuromodulation Integration

```rust
/// Interface for neuromodulation feedback
pub trait NeuromodFeedback {
    /// Notify neuromodulation system of loss update
    fn notify_loss_update(&self, components: &LossComponents, gradient: &LossGradient);

    /// Get modulated learning rate based on loss dynamics
    fn get_modulated_learning_rate(&self) -> f32;
}

/// Stub implementation for Module 10
pub struct NeuromodFeedbackStub;

impl NeuromodFeedback for NeuromodFeedbackStub {
    fn notify_loss_update(&self, _components: &LossComponents, _gradient: &LossGradient) {
        // Stub - Module 10 will implement
    }

    fn get_modulated_learning_rate(&self) -> f32 {
        // Default learning rate per constitution.yaml
        0.001
    }
}
```

### Test Suite

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn composite_loss_formula_correct() {
        let mut loss = CompositeLoss::new(LossConfig::default()).unwrap();

        let predictions = vec![0.5; 100];
        let targets = vec![0.6; 100];
        let signal = LearningSignal {
            learning_magnitude: 0.5,
            ..Default::default()
        };

        let components = loss.compute(
            &predictions,
            &targets,
            &signal,
            &LifecycleStage::Growth,
        ).unwrap();

        // Verify formula: J = 0.4·L_task + 0.3·L_semantic + 0.3·(1-L)
        let expected = 0.4 * components.task_loss
                     + 0.3 * components.semantic_loss
                     + 0.3 * components.learning_loss;

        assert!((components.composite_loss - expected).abs() < 0.001);
    }

    #[test]
    fn loss_components_bounded() {
        let mut loss = CompositeLoss::new(LossConfig::default()).unwrap();

        let signal = LearningSignal {
            learning_magnitude: 0.8,
            ..Default::default()
        };

        let components = loss.compute(
            &[0.1, 0.2, 0.3],
            &[0.9, 0.8, 0.7],
            &signal,
            &LifecycleStage::Infancy,
        ).unwrap();

        assert!(components.task_loss >= 0.0 && components.task_loss <= 1.0);
        assert!(components.semantic_loss >= 0.0 && components.semantic_loss <= 1.0);
        assert!(components.learning_loss >= 0.0 && components.learning_loss <= 1.0);
        assert!(components.composite_loss >= 0.0 && components.composite_loss <= 1.0);
    }

    #[test]
    fn history_tracking_works() {
        let mut loss = CompositeLoss::new(LossConfig {
            history_max_length: 10,
            ..Default::default()
        }).unwrap();

        let signal = LearningSignal::default();

        // Record multiple losses
        for i in 0..15 {
            let _ = loss.compute(
                &[i as f32 / 15.0],
                &[0.5],
                &signal,
                &LifecycleStage::Growth,
            );
        }

        // History should be capped at max length
        assert_eq!(loss.history().len(), 10);
    }

    #[test]
    fn weight_validation() {
        let valid_config = LossConfig {
            lambda_task: 0.5,
            lambda_semantic: 0.3,
            lambda_learning: 0.2,
            ..Default::default()
        };
        assert!(valid_config.validate().is_ok());

        let invalid_config = LossConfig {
            lambda_task: 0.5,
            lambda_semantic: 0.5,
            lambda_learning: 0.5,
            ..Default::default()
        };
        assert!(invalid_config.validate().is_err());
    }

    #[test]
    fn gradient_analysis() {
        let mut loss = CompositeLoss::new(LossConfig::default()).unwrap();

        let signal = LearningSignal::default();

        // Record losses with decreasing values (improvement)
        for i in (0..10).rev() {
            let _ = loss.compute(
                &[i as f32 / 10.0],
                &[0.0],
                &signal,
                &LifecycleStage::Growth,
            );
        }

        let gradient = loss.analyze_gradient(10);

        // Gradient should be negative (loss decreasing)
        assert!(gradient.composite_gradient < 0.0);
    }
}
```

## Performance Targets
- Single loss computation: <100μs
- Gradient analysis: <1ms
- History maintenance: O(1) amortized

## Related Tasks
- M05-T20: Core UTL computation
- M05-T21: LearningSignal source
- M05-T41: Neuromodulation integration (Module 10)

---
*Generated: 2026-01-04*
*Module: 05 - UTL Integration*
*Version: 1.0.0*
