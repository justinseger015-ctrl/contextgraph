# M05-T31: Implement Sentiment Lexicon for Emotional Calculator

```yaml
task_id: M05-T31
title: "Implement Sentiment Lexicon for Emotional Calculator"
module: "module-05-utl-integration"
layer: "integration"
priority: "medium"
status: "pending"
estimated_hours: 2
created: "2026-01-04"
dependencies:
  - M05-T16  # EmotionalWeightCalculator
spec_refs:
  - "SPEC-UTL-005 Section 5.2.1"
file_path: "crates/context-graph-utl/src/emotional/lexicon.rs"
test_file: "crates/context-graph-utl/tests/lexicon_tests.rs"
```

---

## Description

Create a sentiment lexicon data structure for the EmotionalWeightCalculator. This lexicon provides valence and arousal scores for words, enabling text-based emotional analysis without external API calls or file dependencies.

The lexicon is embedded directly in the Rust binary as a compile-time constant HashMap, ensuring O(1) lookup performance and zero runtime I/O overhead.

---

## Implementation Requirements

### Lexicon Data Structure

```rust
use std::collections::HashMap;
use once_cell::sync::Lazy;

/// Sentiment information for a word
#[derive(Debug, Clone, Copy)]
pub struct SentimentEntry {
    /// Valence score: positive (+1) to negative (-1)
    pub valence: f32,
    /// Optional arousal modifier (calm=0 to excited=1)
    pub arousal: Option<f32>,
}

/// Lazy-initialized sentiment lexicon
pub static SENTIMENT_LEXICON: Lazy<HashMap<&'static str, SentimentEntry>> = Lazy::new(|| {
    build_lexicon()
});

/// Arousal keywords for arousal-only detection
pub static AROUSAL_KEYWORDS: Lazy<HashMap<&'static str, f32>> = Lazy::new(|| {
    build_arousal_keywords()
});
```

### Required Functions

| Function | Signature | Description |
|----------|-----------|-------------|
| `get_valence` | `fn get_valence(word: &str) -> Option<f32>` | Look up valence score for word |
| `get_arousal` | `fn get_arousal(word: &str) -> Option<f32>` | Look up arousal score for word |
| `get_sentiment` | `fn get_sentiment(word: &str) -> Option<SentimentEntry>` | Get full sentiment entry |
| `analyze_text` | `fn analyze_text(text: &str) -> TextSentiment` | Analyze entire text |
| `lexicon_size` | `fn lexicon_size() -> usize` | Return number of entries |

### TextSentiment Result

```rust
/// Result of text sentiment analysis
#[derive(Debug, Clone, Default)]
pub struct TextSentiment {
    /// Average valence of matched words [-1, 1]
    pub valence: f32,
    /// Average arousal of matched words [0, 1]
    pub arousal: f32,
    /// Number of words matched in lexicon
    pub matched_words: usize,
    /// Total words analyzed
    pub total_words: usize,
    /// Coverage ratio (matched/total)
    pub coverage: f32,
}
```

---

## Lexicon Categories

### Positive Valence Words (valence > 0)

Minimum 250 positive words organized by intensity:

#### High Positive (0.8 - 1.0)
```rust
// Excellence and perfection
"excellent" => 0.95,
"outstanding" => 0.95,
"exceptional" => 0.90,
"wonderful" => 0.90,
"fantastic" => 0.90,
"brilliant" => 0.88,
"magnificent" => 0.88,
"superb" => 0.85,
"amazing" => 0.85,
"incredible" => 0.85,
"perfect" => 1.0,
"flawless" => 0.95,

// Success and achievement
"success" => 0.85,
"triumph" => 0.88,
"victory" => 0.88,
"achievement" => 0.80,
"accomplish" => 0.80,
"breakthrough" => 0.85,
"mastery" => 0.82,

// Joy and happiness
"happy" => 0.85,
"joyful" => 0.90,
"delighted" => 0.88,
"ecstatic" => 0.95,
"elated" => 0.92,
"thrilled" => 0.88,
"overjoyed" => 0.92,
```

#### Medium Positive (0.4 - 0.8)
```rust
"good" => 0.60,
"nice" => 0.55,
"pleasant" => 0.60,
"helpful" => 0.65,
"useful" => 0.55,
"effective" => 0.60,
"reliable" => 0.65,
"stable" => 0.50,
"comfortable" => 0.60,
"satisfied" => 0.65,
"pleased" => 0.70,
"grateful" => 0.75,
"thankful" => 0.72,
```

#### Low Positive (0.1 - 0.4)
```rust
"okay" => 0.20,
"fine" => 0.25,
"acceptable" => 0.30,
"adequate" => 0.25,
"reasonable" => 0.35,
"fair" => 0.30,
```

### Negative Valence Words (valence < 0)

Minimum 250 negative words organized by intensity:

#### High Negative (-0.8 to -1.0)
```rust
// Errors and failures
"error" => -0.75,
"failed" => -0.80,
"failure" => -0.85,
"crash" => -0.90,
"catastrophe" => -0.95,
"disaster" => -0.95,
"fatal" => -0.95,
"critical" => -0.70, // Context-dependent

// Danger and threat
"danger" => -0.85,
"dangerous" => -0.85,
"threat" => -0.80,
"hazard" => -0.75,
"risk" => -0.50,
"warning" => -0.60,
"alert" => -0.55,
"emergency" => -0.85,

// Problems
"problem" => -0.60,
"issue" => -0.45,
"bug" => -0.55,
"broken" => -0.75,
"corrupt" => -0.80,
"malformed" => -0.65,
```

#### Medium Negative (-0.4 to -0.8)
```rust
"bad" => -0.60,
"wrong" => -0.55,
"incorrect" => -0.50,
"invalid" => -0.55,
"missing" => -0.50,
"incomplete" => -0.45,
"slow" => -0.40,
"confusing" => -0.55,
"difficult" => -0.45,
"complicated" => -0.40,
"frustrating" => -0.65,
"annoying" => -0.55,
```

#### Low Negative (-0.1 to -0.4)
```rust
"minor" => -0.20,
"slight" => -0.15,
"uncertain" => -0.25,
"unclear" => -0.30,
"ambiguous" => -0.25,
```

### Arousal Keywords

Words that indicate high arousal (excitement, urgency):

```rust
// High arousal (0.7 - 1.0)
"urgent" => 0.90,
"immediately" => 0.85,
"critical" => 0.85,
"emergency" => 0.95,
"asap" => 0.85,
"now" => 0.70,
"hurry" => 0.80,
"quick" => 0.65,
"fast" => 0.60,
"exciting" => 0.80,
"thrilling" => 0.85,
"shocking" => 0.90,
"amazing" => 0.75,
"incredible" => 0.75,

// Medium arousal (0.4 - 0.7)
"important" => 0.55,
"significant" => 0.50,
"notable" => 0.45,
"interesting" => 0.50,
"surprising" => 0.60,

// Low arousal (0.1 - 0.4)
"calm" => 0.20,
"quiet" => 0.15,
"peaceful" => 0.20,
"steady" => 0.25,
"stable" => 0.20,
"relaxed" => 0.15,
```

---

## Text Analysis Algorithm

### `analyze_text` Implementation

```rust
pub fn analyze_text(text: &str) -> TextSentiment {
    let words: Vec<&str> = text
        .to_lowercase()
        .split(|c: char| !c.is_alphanumeric())
        .filter(|w| !w.is_empty())
        .collect();

    let total_words = words.len();
    if total_words == 0 {
        return TextSentiment::default();
    }

    let mut valence_sum = 0.0;
    let mut arousal_sum = 0.0;
    let mut valence_count = 0;
    let mut arousal_count = 0;

    for word in &words {
        if let Some(entry) = SENTIMENT_LEXICON.get(word) {
            valence_sum += entry.valence;
            valence_count += 1;
            if let Some(arousal) = entry.arousal {
                arousal_sum += arousal;
                arousal_count += 1;
            }
        }

        // Check arousal keywords separately
        if let Some(&arousal) = AROUSAL_KEYWORDS.get(word) {
            if arousal_count == 0 || !SENTIMENT_LEXICON.contains_key(word) {
                arousal_sum += arousal;
                arousal_count += 1;
            }
        }
    }

    let matched_words = valence_count.max(arousal_count);

    TextSentiment {
        valence: if valence_count > 0 { valence_sum / valence_count as f32 } else { 0.0 },
        arousal: if arousal_count > 0 { arousal_sum / arousal_count as f32 } else { 0.0 },
        matched_words,
        total_words,
        coverage: matched_words as f32 / total_words as f32,
    }
}
```

### Punctuation Arousal Heuristics

These heuristics augment the lexicon-based analysis:

```rust
/// Compute arousal from punctuation patterns
pub fn analyze_punctuation_arousal(text: &str) -> f32 {
    let mut arousal = 0.0;

    // Exclamation marks increase arousal
    let exclamation_count = text.matches('!').count();
    arousal += (exclamation_count as f32 * 0.15).min(0.5);

    // ALL CAPS words increase arousal
    let caps_words = text.split_whitespace()
        .filter(|w| w.len() > 2 && w.chars().all(|c| c.is_uppercase()))
        .count();
    arousal += (caps_words as f32 * 0.1).min(0.4);

    // Question marks slightly increase arousal
    let question_count = text.matches('?').count();
    arousal += (question_count as f32 * 0.05).min(0.2);

    arousal.min(1.0)
}
```

---

## Acceptance Criteria

- [ ] Sentiment lexicon with 500+ words total
- [ ] Each word has valence score in range [-1, 1]
- [ ] Positive words: minimum 250 entries
- [ ] Negative words: minimum 250 entries
- [ ] Arousal keywords identified separately (50+ entries)
- [ ] Lookup is O(1) via HashMap
- [ ] Embedded in binary (no runtime file I/O)
- [ ] `analyze_text` correctly computes average valence/arousal
- [ ] `analyze_punctuation_arousal` handles !, ?, CAPS
- [ ] Unit tests verify lexicon coverage and correctness

---

## Test Cases

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_lexicon_size() {
        assert!(lexicon_size() >= 500);
    }

    #[test]
    fn test_positive_valence() {
        assert!(get_valence("excellent").unwrap() > 0.8);
        assert!(get_valence("good").unwrap() > 0.5);
        assert!(get_valence("okay").unwrap() > 0.0);
    }

    #[test]
    fn test_negative_valence() {
        assert!(get_valence("error").unwrap() < -0.5);
        assert!(get_valence("failed").unwrap() < -0.7);
        assert!(get_valence("catastrophe").unwrap() < -0.9);
    }

    #[test]
    fn test_arousal_keywords() {
        assert!(get_arousal("urgent").unwrap() > 0.8);
        assert!(get_arousal("calm").unwrap() < 0.3);
    }

    #[test]
    fn test_analyze_text_positive() {
        let result = analyze_text("This is an excellent and wonderful solution!");
        assert!(result.valence > 0.7);
        assert!(result.matched_words >= 2);
    }

    #[test]
    fn test_analyze_text_negative() {
        let result = analyze_text("Critical error: system failure detected");
        assert!(result.valence < -0.5);
    }

    #[test]
    fn test_analyze_text_mixed() {
        let result = analyze_text("Good progress but some problems remain");
        // Should be slightly positive or neutral due to mixing
        assert!(result.valence > -0.3 && result.valence < 0.5);
    }

    #[test]
    fn test_punctuation_arousal() {
        assert!(analyze_punctuation_arousal("URGENT!!!") > 0.5);
        assert!(analyze_punctuation_arousal("okay") < 0.1);
    }

    #[test]
    fn test_case_insensitivity() {
        assert_eq!(get_valence("EXCELLENT"), get_valence("excellent"));
        assert_eq!(get_valence("Error"), get_valence("error"));
    }

    #[test]
    fn test_unknown_word() {
        assert!(get_valence("xyzabc123").is_none());
    }
}
```

---

## File Structure

```
crates/context-graph-utl/
  src/
    emotional/
      mod.rs            <- Add pub mod lexicon;
      lexicon.rs        <- Implementation file (this task)
      calculator.rs     <- Uses lexicon (from M05-T16)
  tests/
    lexicon_tests.rs    <- Test file
```

---

## Dependencies

- `once_cell`: Lazy static initialization
- `std::collections::HashMap`: Lexicon storage

---

## Performance Requirements

- Lexicon lookup: O(1) constant time
- `analyze_text`: O(n) where n = word count
- Memory: ~50KB for embedded lexicon
- No runtime file I/O

---

## Notes

- The lexicon is intentionally embedded to avoid file system dependencies in production
- Valence scores are based on general sentiment analysis conventions
- Domain-specific terms (programming, technical) have appropriate technical sentiment scores
- The lexicon can be extended in future tasks with domain-specific vocabularies
- Case-insensitive matching is required for robustness
